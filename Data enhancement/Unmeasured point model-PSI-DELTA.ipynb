{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\hxc\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 标准库\n",
    "import time\n",
    "from math import sqrt\n",
    "import os\n",
    "\n",
    "# 第三方库\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from IPython.display import display\n",
    "\n",
    "#三大类别数据回归算法\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Scikit-learn 库\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import BayesianRidge, ElasticNet, LinearRegression, Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import Binarizer, MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "sns.set(font='serif', style='ticks')\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['font.sans-serif']=['Arial Unicode MS']\n",
    "\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.optimizers import Adam,Adamax,Nadam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D,MaxPooling1D, MaxPooling2D,GlobalAveragePooling1D,Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取文件\n",
    "data1 = pd.read_csv('./Vm_vce.csv')\n",
    "data2 = pd.read_csv('./Vm.csv')\n",
    "\n",
    "X = data1[['m','c','v']]\n",
    "Y1 = data2[['PSI', 'DELTA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer1 = StandardScaler()\n",
    "X = transfer1.fit_transform(X)\n",
    "\n",
    "transfer2 = StandardScaler()\n",
    "Y1 = transfer2.fit_transform(Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(606, 701, 2)\n"
     ]
    }
   ],
   "source": [
    "samples_per_slice = 701\n",
    "n_samples = Y1.shape[0] // samples_per_slice\n",
    "feature_slices_Y1 = Y1[:n_samples * samples_per_slice].reshape((n_samples, samples_per_slice, 2))\n",
    "Y1 = np.stack(feature_slices_Y1, axis=0)\n",
    "print(Y1.shape)  # (110, 701, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test =train_test_split(X, Y1, test_size=0.2, random_state=37,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 512)               2048      \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVec  (None, 701, 512)          0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 698, 128)          262272    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 349, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 346, 16)           8208      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 173, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 168, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 84, 16)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 82, 32)            1568      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 41, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 35, 16)            3600      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 17, 16)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 17, 16)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 272)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1402)              382746    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 701, 2)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 661994 (2.53 MB)\n",
      "Trainable params: 661994 (2.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Reshape, Dropout, RepeatVector\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "l2_reg = l2(1.6012496073680687e-93)\n",
    "# 建立序列预测模型\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(3,)))\n",
    "model.add(RepeatVector(701))  # 将输入重复seq_length次来匹配输出的时间步长\n",
    "model.add(Conv1D(filters=128, kernel_size=4, activation='relu', kernel_regularizer=l2_reg))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=16, kernel_size=4, activation='relu', kernel_regularizer=l2_reg))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=16, kernel_size=6, activation='relu', kernel_regularizer=l2_reg))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', kernel_regularizer=l2_reg))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=16, kernel_size=7, activation='relu', kernel_regularizer=l2_reg))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.05195500021948446))\n",
    "model.add(Flatten())\n",
    "\n",
    "# 通过添加另一个Dense层，然后使用Reshape层调整形状为(701, 2)\n",
    "model.add(Dense(701 * 2))\n",
    "model.add(Reshape((701, 2)))\n",
    "\n",
    "# 输出模型结构\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=79, verbose=1, min_delta=0.00001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 4s 38ms/step - loss: 0.9572 - val_loss: 1.0356\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9463 - val_loss: 1.0167\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9147 - val_loss: 0.9634\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8504 - val_loss: 0.8662\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.7550 - val_loss: 0.7644\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6677 - val_loss: 0.6747\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5965 - val_loss: 0.6008\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5424 - val_loss: 0.5546\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5068 - val_loss: 0.5263\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4856 - val_loss: 0.5055\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4705 - val_loss: 0.4873\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4572 - val_loss: 0.4719\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4414 - val_loss: 0.4587\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4275 - val_loss: 0.4432\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4129 - val_loss: 0.4287\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4013 - val_loss: 0.4139\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3856 - val_loss: 0.4021\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3742 - val_loss: 0.3907\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3636 - val_loss: 0.3804\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3509 - val_loss: 0.3708\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3398 - val_loss: 0.3618\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3317 - val_loss: 0.3523\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3212 - val_loss: 0.3438\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3136 - val_loss: 0.3384\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3087 - val_loss: 0.3330\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3020 - val_loss: 0.3265\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2950 - val_loss: 0.3233\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2904 - val_loss: 0.3169\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2843 - val_loss: 0.3139\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2812 - val_loss: 0.3085\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2753 - val_loss: 0.3080\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2719 - val_loss: 0.3031\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2704 - val_loss: 0.2986\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2650 - val_loss: 0.2968\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2623 - val_loss: 0.2921\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2596 - val_loss: 0.2881\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2524 - val_loss: 0.2844\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2501 - val_loss: 0.2803\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2468 - val_loss: 0.2769\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2410 - val_loss: 0.2726\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2371 - val_loss: 0.2711\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2337 - val_loss: 0.2658\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2290 - val_loss: 0.2621\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2273 - val_loss: 0.2579\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2239 - val_loss: 0.2560\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2176 - val_loss: 0.2533\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2159 - val_loss: 0.2491\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2126 - val_loss: 0.2443\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2063 - val_loss: 0.2442\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2057 - val_loss: 0.2399\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2008 - val_loss: 0.2387\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1970 - val_loss: 0.2297\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1921 - val_loss: 0.2273\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1910 - val_loss: 0.2250\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1851 - val_loss: 0.2239\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1838 - val_loss: 0.2159\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1832 - val_loss: 0.2154\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1774 - val_loss: 0.2133\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1748 - val_loss: 0.2094\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1702 - val_loss: 0.2062\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1696 - val_loss: 0.2040\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1662 - val_loss: 0.2023\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1642 - val_loss: 0.2010\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1601 - val_loss: 0.1979\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1605 - val_loss: 0.1953\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1562 - val_loss: 0.1946\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1553 - val_loss: 0.1922\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1543 - val_loss: 0.1890\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1518 - val_loss: 0.1869\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1499 - val_loss: 0.1892\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1475 - val_loss: 0.1836\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1457 - val_loss: 0.1840\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1444 - val_loss: 0.1822\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1433 - val_loss: 0.1815\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1416 - val_loss: 0.1792\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1404 - val_loss: 0.1779\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1409 - val_loss: 0.1735\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1401 - val_loss: 0.1745\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1389 - val_loss: 0.1734\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1360 - val_loss: 0.1750\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1360 - val_loss: 0.1727\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1325 - val_loss: 0.1694\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1320 - val_loss: 0.1701\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1300 - val_loss: 0.1676\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1319 - val_loss: 0.1677\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1292 - val_loss: 0.1683\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1287 - val_loss: 0.1654\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1289 - val_loss: 0.1625\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1262 - val_loss: 0.1656\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1242 - val_loss: 0.1661\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1247 - val_loss: 0.1620\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1235 - val_loss: 0.1608\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1227 - val_loss: 0.1604\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1206 - val_loss: 0.1597\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1212 - val_loss: 0.1599\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1192 - val_loss: 0.1577\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1209 - val_loss: 0.1567\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1179 - val_loss: 0.1551\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1192 - val_loss: 0.1613\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1189 - val_loss: 0.1509\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1244 - val_loss: 0.1575\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1194 - val_loss: 0.1531\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1192 - val_loss: 0.1592\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1151 - val_loss: 0.1517\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1128 - val_loss: 0.1525\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1119 - val_loss: 0.1517\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1106 - val_loss: 0.1522\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1104 - val_loss: 0.1501\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1105 - val_loss: 0.1514\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1104 - val_loss: 0.1518\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1097 - val_loss: 0.1521\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1085 - val_loss: 0.1521\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1059 - val_loss: 0.1475\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1048 - val_loss: 0.1487\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1057 - val_loss: 0.1486\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1050 - val_loss: 0.1480\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1056 - val_loss: 0.1426\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1034 - val_loss: 0.1542\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1045 - val_loss: 0.1470\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1025 - val_loss: 0.1433\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1027 - val_loss: 0.1449\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1018 - val_loss: 0.1459\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0996 - val_loss: 0.1454\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1004 - val_loss: 0.1443\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0991 - val_loss: 0.1417\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0985 - val_loss: 0.1414\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0962 - val_loss: 0.1417\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1364\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0952 - val_loss: 0.1430\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0944 - val_loss: 0.1407\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0956 - val_loss: 0.1400\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0959 - val_loss: 0.1377\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0947 - val_loss: 0.1399\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0934 - val_loss: 0.1397\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0937 - val_loss: 0.1377\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0928 - val_loss: 0.1384\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0917 - val_loss: 0.1386\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0914 - val_loss: 0.1357\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0919 - val_loss: 0.1353\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0914 - val_loss: 0.1355\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0886 - val_loss: 0.1391\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0893 - val_loss: 0.1351\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0896 - val_loss: 0.1364\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0880 - val_loss: 0.1357\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0880 - val_loss: 0.1363\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0872 - val_loss: 0.1361\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0864 - val_loss: 0.1330\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0875 - val_loss: 0.1351\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0867 - val_loss: 0.1365\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0869 - val_loss: 0.1310\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0858 - val_loss: 0.1368\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0878 - val_loss: 0.1309\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0855 - val_loss: 0.1361\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0867 - val_loss: 0.1335\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0835 - val_loss: 0.1332\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0829 - val_loss: 0.1296\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0817 - val_loss: 0.1336\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0817 - val_loss: 0.1304\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0810 - val_loss: 0.1322\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0821 - val_loss: 0.1299\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0824 - val_loss: 0.1317\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0852 - val_loss: 0.1290\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0809 - val_loss: 0.1293\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0799 - val_loss: 0.1272\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0808 - val_loss: 0.1300\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0800 - val_loss: 0.1308\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0811 - val_loss: 0.1299\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0788 - val_loss: 0.1309\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0776 - val_loss: 0.1293\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0794 - val_loss: 0.1281\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0776 - val_loss: 0.1240\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0777 - val_loss: 0.1279\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0760 - val_loss: 0.1275\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0772 - val_loss: 0.1243\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0791 - val_loss: 0.1346\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0762 - val_loss: 0.1284\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0760 - val_loss: 0.1308\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0759 - val_loss: 0.1256\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0750 - val_loss: 0.1299\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0731 - val_loss: 0.1261\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0748 - val_loss: 0.1319\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0736 - val_loss: 0.1300\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0743 - val_loss: 0.1308\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0729 - val_loss: 0.1289\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0745 - val_loss: 0.1270\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0724 - val_loss: 0.1278\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0726 - val_loss: 0.1272\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0706 - val_loss: 0.1265\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0712 - val_loss: 0.1248\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0715 - val_loss: 0.1238\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0707 - val_loss: 0.1295\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0722 - val_loss: 0.1227\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0721 - val_loss: 0.1227\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0718 - val_loss: 0.1272\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0696 - val_loss: 0.1264\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0696 - val_loss: 0.1212\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0685 - val_loss: 0.1254\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0697 - val_loss: 0.1240\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0685 - val_loss: 0.1272\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0697 - val_loss: 0.1223\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0683 - val_loss: 0.1202\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0677 - val_loss: 0.1297\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0676 - val_loss: 0.1187\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0679 - val_loss: 0.1220\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0684 - val_loss: 0.1289\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0678 - val_loss: 0.1208\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0676 - val_loss: 0.1265\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0703 - val_loss: 0.1168\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0679 - val_loss: 0.1272\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0653 - val_loss: 0.1209\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0672 - val_loss: 0.1227\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0659 - val_loss: 0.1215\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0646 - val_loss: 0.1256\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0657 - val_loss: 0.1252\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0667 - val_loss: 0.1194\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0654 - val_loss: 0.1225\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0640 - val_loss: 0.1230\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0626 - val_loss: 0.1247\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0625 - val_loss: 0.1218\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0638 - val_loss: 0.1241\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0636 - val_loss: 0.1240\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0618 - val_loss: 0.1192\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0644 - val_loss: 0.1257\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0616 - val_loss: 0.1231\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0622 - val_loss: 0.1219\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0625 - val_loss: 0.1190\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0617 - val_loss: 0.1208\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0622 - val_loss: 0.1196\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0615 - val_loss: 0.1197\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0606 - val_loss: 0.1222\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0602 - val_loss: 0.1226\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0596 - val_loss: 0.1210\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0600 - val_loss: 0.1247\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0616 - val_loss: 0.1137\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0620 - val_loss: 0.1244\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0605 - val_loss: 0.1188\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0609 - val_loss: 0.1202\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0615 - val_loss: 0.1197\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0594 - val_loss: 0.1230\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0585 - val_loss: 0.1183\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0597 - val_loss: 0.1231\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0582 - val_loss: 0.1162\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0589 - val_loss: 0.1210\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0592 - val_loss: 0.1191\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0580 - val_loss: 0.1206\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0580 - val_loss: 0.1160\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0579 - val_loss: 0.1177\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0609 - val_loss: 0.1229\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0592 - val_loss: 0.1207\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0572 - val_loss: 0.1219\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0580 - val_loss: 0.1138\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0570 - val_loss: 0.1168\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0576 - val_loss: 0.1165\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0559 - val_loss: 0.1203\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0560 - val_loss: 0.1156\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0555 - val_loss: 0.1201\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0548 - val_loss: 0.1211\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0546 - val_loss: 0.1190\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0558 - val_loss: 0.1161\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0544 - val_loss: 0.1142\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0554 - val_loss: 0.1236\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0567 - val_loss: 0.1253\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0566 - val_loss: 0.1127\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0556 - val_loss: 0.1231\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0537 - val_loss: 0.1147\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0553 - val_loss: 0.1316\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0569 - val_loss: 0.1125\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0550 - val_loss: 0.1238\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0549 - val_loss: 0.1173\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0537 - val_loss: 0.1177\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0530 - val_loss: 0.1232\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0537 - val_loss: 0.1136\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0529 - val_loss: 0.1204\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0539 - val_loss: 0.1158\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0529 - val_loss: 0.1215\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0530 - val_loss: 0.1165\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0529 - val_loss: 0.1180\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0547 - val_loss: 0.1122\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0553 - val_loss: 0.1304\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0538 - val_loss: 0.1152\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0538 - val_loss: 0.1208\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0535 - val_loss: 0.1165\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0515 - val_loss: 0.1200\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0509 - val_loss: 0.1160\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0510 - val_loss: 0.1222\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0540 - val_loss: 0.1271\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0521 - val_loss: 0.1171\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0518 - val_loss: 0.1119\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0535 - val_loss: 0.1155\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0501 - val_loss: 0.1148\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0503 - val_loss: 0.1300\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0527 - val_loss: 0.1178\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0518 - val_loss: 0.1220\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0513 - val_loss: 0.1211\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0520 - val_loss: 0.1132\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0508 - val_loss: 0.1211\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0514 - val_loss: 0.1156\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0495 - val_loss: 0.1200\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0503 - val_loss: 0.1120\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0497 - val_loss: 0.1153\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0495 - val_loss: 0.1149\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0489 - val_loss: 0.1165\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0488 - val_loss: 0.1179\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0486 - val_loss: 0.1160\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0487 - val_loss: 0.1153\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0486 - val_loss: 0.1242\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0501 - val_loss: 0.1177\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0496 - val_loss: 0.1138\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0489 - val_loss: 0.1179\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0475 - val_loss: 0.1170\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0526 - val_loss: 0.1127\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0527 - val_loss: 0.1282\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0514 - val_loss: 0.1124\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0508 - val_loss: 0.1224\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0500 - val_loss: 0.1220\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0487 - val_loss: 0.1134\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0470 - val_loss: 0.1158\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0474 - val_loss: 0.1125\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0477 - val_loss: 0.1183\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0466 - val_loss: 0.1185\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0475 - val_loss: 0.1116\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0496 - val_loss: 0.1152\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0494 - val_loss: 0.1210\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0467 - val_loss: 0.1131\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0466 - val_loss: 0.1189\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0467 - val_loss: 0.1128\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0485 - val_loss: 0.1168\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0465 - val_loss: 0.1163\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0460 - val_loss: 0.1149\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0470 - val_loss: 0.1169\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0467 - val_loss: 0.1142\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0470 - val_loss: 0.1160\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0465 - val_loss: 0.1186\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0456 - val_loss: 0.1085\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0464 - val_loss: 0.1264\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0471 - val_loss: 0.1133\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0458 - val_loss: 0.1210\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0455 - val_loss: 0.1157\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0454 - val_loss: 0.1190\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0441 - val_loss: 0.1098\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0467 - val_loss: 0.1223\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0462 - val_loss: 0.1132\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0468 - val_loss: 0.1230\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0488 - val_loss: 0.1182\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0458 - val_loss: 0.1141\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0449 - val_loss: 0.1186\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0448 - val_loss: 0.1118\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0474 - val_loss: 0.1239\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0450 - val_loss: 0.1120\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0456 - val_loss: 0.1164\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0447 - val_loss: 0.1185\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0450 - val_loss: 0.1245\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0447 - val_loss: 0.1121\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0458 - val_loss: 0.1104\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0464 - val_loss: 0.1208\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0451 - val_loss: 0.1140\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0433 - val_loss: 0.1178\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0447 - val_loss: 0.1167\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0463 - val_loss: 0.1105\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0452 - val_loss: 0.1196\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0436 - val_loss: 0.1122\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0449 - val_loss: 0.1244\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0431 - val_loss: 0.1123\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0438 - val_loss: 0.1189\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0436 - val_loss: 0.1111\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0450 - val_loss: 0.1252\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0447 - val_loss: 0.1115\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0439 - val_loss: 0.1138\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0431 - val_loss: 0.1177\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0430 - val_loss: 0.1115\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0444 - val_loss: 0.1239\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0427 - val_loss: 0.1102\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0438 - val_loss: 0.1190\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0447 - val_loss: 0.1066\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0468 - val_loss: 0.1227\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0433 - val_loss: 0.1106\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0427 - val_loss: 0.1261\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0422 - val_loss: 0.1151\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0417 - val_loss: 0.1114\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0424 - val_loss: 0.1143\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0431 - val_loss: 0.1172\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0440 - val_loss: 0.1089\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0436 - val_loss: 0.1179\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0412 - val_loss: 0.1152\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0426 - val_loss: 0.1229\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0434 - val_loss: 0.1103\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0433 - val_loss: 0.1161\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0424 - val_loss: 0.1150\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0416 - val_loss: 0.1169\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0421 - val_loss: 0.1153\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0434 - val_loss: 0.1141\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0436 - val_loss: 0.1234\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0425 - val_loss: 0.1149\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0421 - val_loss: 0.1106\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0435 - val_loss: 0.1290\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0428 - val_loss: 0.1138\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0407 - val_loss: 0.1096\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0428 - val_loss: 0.1217\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0415 - val_loss: 0.1163\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0420 - val_loss: 0.1136\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0421 - val_loss: 0.1202\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0411 - val_loss: 0.1148\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0409 - val_loss: 0.1187\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0416 - val_loss: 0.1139\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0410 - val_loss: 0.1055\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0419 - val_loss: 0.1252\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0404 - val_loss: 0.1095\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0420 - val_loss: 0.1200\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0422 - val_loss: 0.1185\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0405 - val_loss: 0.1184\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0423 - val_loss: 0.1191\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0419 - val_loss: 0.1147\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0417 - val_loss: 0.1132\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0406 - val_loss: 0.1186\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0429 - val_loss: 0.1164\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0411 - val_loss: 0.1099\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0411 - val_loss: 0.1135\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0408 - val_loss: 0.1164\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0408 - val_loss: 0.1177\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0400 - val_loss: 0.1124\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0413 - val_loss: 0.1189\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0401 - val_loss: 0.1153\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0410 - val_loss: 0.1189\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0406 - val_loss: 0.1109\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0395 - val_loss: 0.1235\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0384 - val_loss: 0.1126\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0390 - val_loss: 0.1208\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0399 - val_loss: 0.1121\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0392 - val_loss: 0.1160\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0391 - val_loss: 0.1176\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0391 - val_loss: 0.1189\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0386 - val_loss: 0.1120\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0414 - val_loss: 0.1206\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0397 - val_loss: 0.1121\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0388 - val_loss: 0.1137\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0404 - val_loss: 0.1139\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0389 - val_loss: 0.1166\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0405 - val_loss: 0.1092\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0415 - val_loss: 0.1174\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0413 - val_loss: 0.1080\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0403 - val_loss: 0.1300\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0404 - val_loss: 0.1075\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0396 - val_loss: 0.1191\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0422 - val_loss: 0.1080\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0417 - val_loss: 0.1192\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0394 - val_loss: 0.1089\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0385 - val_loss: 0.1177\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0380 - val_loss: 0.1181\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0390 - val_loss: 0.1117\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0396 - val_loss: 0.1201\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0388 - val_loss: 0.1110\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.1119\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0400 - val_loss: 0.1300\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0400 - val_loss: 0.1146\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0400 - val_loss: 0.1136\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0394 - val_loss: 0.1148\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0395 - val_loss: 0.1117\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0395 - val_loss: 0.1250\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.1093\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.1291\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0404 - val_loss: 0.1170\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.1149\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0371 - val_loss: 0.1160\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0383 - val_loss: 0.1209\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0366 - val_loss: 0.1128\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.1169\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0377 - val_loss: 0.1164\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0381 - val_loss: 0.1120\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0377 - val_loss: 0.1214\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0384 - val_loss: 0.1057\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0393 - val_loss: 0.1292\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0376 - val_loss: 0.1081\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0385 - val_loss: 0.1127\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0389 - val_loss: 0.1160\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0375 - val_loss: 0.1116\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0377 - val_loss: 0.1215\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0371 - val_loss: 0.1137\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0371 - val_loss: 0.1122\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0373 - val_loss: 0.1198\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0390 - val_loss: 0.1087\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0368 - val_loss: 0.1245\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0375 - val_loss: 0.1066\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0393 - val_loss: 0.1247\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0366 - val_loss: 0.1149\n",
      "Epoch 484: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 编译模型，使用MSE损失函数和SGD优化器\n",
    "model.compile(loss='mean_squared_error', optimizer=Adamax(learning_rate=0.00013682016083260972))\n",
    "\n",
    "# 训练模型，假设训练数据为X_train和y_train\n",
    "history = model.fit(x_train, y_train, callbacks=callbacks,epochs=1000, batch_size=16, validation_split=0.4162773993435479)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHMCAYAAADF4Oz/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6sElEQVR4nO3dd3xV9f3H8dfdN3sQEsKGsBFQRARFVLaKUqwKzvqrilao1m21ta11VepARKxV6yi4sC4ElSVDQAFZyg6Emb3nnef3xzUXYkJkhNwLeT8fDx+enHvOuZ9zckne+X6/53tMhmEYiIiIiEidzKEuQERERCScKSyJiIiI1ENhSURERKQeCksiIiIi9VBYEhEREamHwpKIiIhIPRSWREREROqhsCQiIiJSD4UlERERkXooLInISe3GG2/k3HPPpWvXrke97x/+8AcuuOACunbtyr59+05AdSJyKlBYEpFjlp2dzZgxY4Jh5e677653+0WLFtG1a1f69+/PmDFj2Lx583HX8MYbbzB+/Phj2vf555/njjvuOKJt77nnHoYPH07Xrl254IILuPHGG4/pPUXk5KOwJCLHLCUlhU8++YTx48djMpmYO3cu6enph93+pZdeAmDIkCF88skndO/evbFKPW7PPPMMjz32GAB33HEHb7zxRmgLEpFGo7AkIg1i+PDhGIYRDEQ/t2jRIlq2bNnIVYmIHD9rqAsQkVNDly5dAJgzZw633347aWlpNV6fNm0ajz/+OF988UWd++/evZtnn32W9evXY7fbiY6O5pZbbuGiiy6qsd2WLVt4/PHH2bZtG23atOGcc87BbK77774lS5bw4osvUlhYiM/n47TTTuO+++6jTZs2DXDG9cvLy+PZZ59lxYoV2O12bDYbV199Nddee21wG6/Xy4svvsiCBQuwWq14vV569uzJb37zm2Cr24YNG3j22WcpKioCwOl0MnToUG655ZYTfg4iEqCWJRFpMBMnTqyzdWnRokWkpqYedhD2/v37ueqqq7DZbMyfP5+vvvqKiRMncs899/DOO+8EtysuLuY3v/kNERERLF26lFmzZtG7d28++OCDWsecN28et956K2PGjGHevHl89dVXWCwWrr322mDwOFFKSkq45pprOHDgAJ9//jlffvkljz32GM888wz//Oc/g9v9+9//Zv78+bz33nt89NFHvPPOO+zZs4f58+cDUFZWxs0338xll13Gxx9/zMcff8xvf/vbGscQkRNPYUlEGky3bt0YOnQoc+bMYefOncH106ZNY+LEiYfdb+rUqZSXl/PQQw9htQYavIcOHcrgwYP55z//SXl5ORAYzF1UVMR9992H3W4HYNiwYXTu3LnG8QzD4Mknn6Rjx47Blhyr1cr9999PdnY2M2bMaNDz/rk333yT3bt38+CDDxIZGQnA6aefzuWXX87rr7/O3r17AVi3bh3NmzcPbhMdHc3dd99Nnz59ANi1axfFxcW0a9cueOwRI0Zw2223ndD6RaQmhSURaVATJ07E7/cHW5cWLVpEcnIy3bp1O+w+y5Yto3Xr1iQmJtZYf8YZZ1BWVsbatWsB+P7773E6nbXCUXUXYLVdu3axf/9+zjzzzBrrU1NTiYmJYeXKlcd8fkdi2bJlOByOWud8+umn4/P5WL58OQADBw5k+fLl3HTTTcyZM4eysjL69evH4MGDAejYsSMpKSncfvvtPP/882zZsgWAu+6664TWLyI1acySiDSoHj16cOGFFwbHLk2bNo2//e1v9e5TWFhI69ata62Pj48HoKCgAICcnBxiY2NrbRcTE1PreAALFixg/fr1NV6LiIjA6/Ue8fkci8LCwjrr/Pn53HjjjSQnJzNz5kzuvvturFYrI0eO5MEHH6R58+ZERUXxwQcf8Oqrr/Lee+8xffp02rdvz+9+9zt+9atfndBzEJGDFJZEpMFNnDiRRYsWMXHiRNq1a0fPnj3r3T4hIaHOcUTV66pbnJKTkzlw4ECt7UpKSmodD+CSSy7hoYceOoYzOHqGYeDxeLDb7SQkJJCVlVVrm5+fD8DFF1/MxRdfTGZmJh9++CGvvPIKmZmZzJw5EwhMz/Dwww/zwAMP8M033zB9+nQeeOABUlJSGDhwYKOcm0hTp244EWlwvXr14vzzz2fnzp3cfvvtv7j9oEGD2LdvX7DFpdq6deuIjo7mjDPOAKBv375UVVWxbdu2Gtv9/OsOHTrQqlWrOie9fO+9907ImKX9+/czatQoIHA+Lpcr2G1Wbd26dVgsFs455xwgMHdT9fil1NRUJk2axFVXXRXcb+vWrUyfPh0IjLk6//zzefnllwFqHVtEThyFJRE5If7+978zY8YMevfu/YvbTpo0iaioKP7xj38Eu8gWLVrE4sWLuffee4mKigIC3Vbx8fH885//xO12AzB//nw2bNhQ43gmk4mHH36Y1atX8+GHHwbXr1u3jhdeeOGIajoev/nNb2jbti1PP/00FRUVQGAKgP/973/89re/DU5dsG7dOv7zn/8Ez7m8vJyNGzcGw1RRURH/+c9/2LFjR/DY3377LVarlf79+5/QcxCRg0yGYRihLkJETk5VVVWMGzeOvLw8AJKSknjvvfdwOp21tn3jjTf46KOP2LJlC3FxcaSmpjJ16lTatm0LBOZZeuaZZ9iwYQM2m42YmBhuvvlmLr744hrH2bp1K4899hjbtm2jVatW9OnTh+joaF555RW6devGrbfeGtznm2++4cUXXyQrK4uEhARiY2OZNGkS/fr1AwLPhlu3bh2ZmZmkpaUxfvx4brjhhjrP9bbbbmPjxo3k5eURHx8fDHDVvF4vVquVhQsXAoF5lp555hlWrFiBw+HAarVyzTXX1JhnacGCBbz33nvs378/OM/SgAED+MMf/kBMTAwFBQW8+uqrLFu2DLPZjN/vJzIykt/97necf/75x/ItE5FjoLAkIiIiUg91w4mIiIjUQ2FJREREpB4KSyIiIiL1UFgSERERqYfCkoiIiEg9FJZERERE6qHHndSjX79+uN1umjdvHupSRERE5Ajl5uZit9tZvXp1gxxPYakeLpcLn88X6jJERETkKHi9XhpyGkmFpXokJycDgVl2RURE5OQwdOjQBj2exiyJiIiI1ENhSURERKQeCksiIiIi9VBYEhEREamHBniLiJzifD4fHo8n1GWINBibzYbFYmm091NYEhE5RRmGQVZWFkVFRaEuRaTBxcfH06JFC0wm0wl/L4UlEZFTVHVQSk5OJjIyslF+qYicaIZhUFFRQU5ODgCpqakn/D0VlkRETkE+ny8YlJo1axbqckQaVEREBAA5OTkkJyef8C45DfAWETkFVY9RioyMDHElIidG9We7McbjKSyJiJzC1PUmp6rG/GwrLImIiIjUQ2FJREREpB4a4C0iImFryJAh2Gw2bDYbALt378btdgPQvn374PqMjAy++OILWrdufdzvuWrVKu644w46duzI66+/jsPhOOpjzJkzh0ceeYRzzjmHF1544bhrOlpPPvkk8+bNY//+/QDExsaSkpLCrFmzcDqdjV7PyU5hKURK1s7HGp1AZOczQ12KiEhYe+2114IhaPTo0Wzfvr3W+iFDhjTY+33xxRcUFBRQUFDA9u3bOe200476GJ9++imlpaV8+eWXFBYWkpCQ0GD1HYk//vGPDBkyhBtuuAGAoUOH8tRTTzVqDacShaUQ8FeVkzdnOiabk/b3voXJ3HizkIqInExGjhx5RHf0Hel2R2L8+PFs3ryZDh060L1792M6xk033UR+fj4DBw5s9KAkDU9hKQRMdidYrBieKrwl+djik0Ndkog0EYZh4HL7Qvb+DrvlqO5ieuCBB45ou86dO3PFFVcEu53uuusuNm/ezNatW9m1axfTpk2jtLSUGTNm4HK5KCsro6Kigj59+jBp0iR69+4NwIwZM/jXv/5FdnY2a9as4bLLLuPss8/mj3/8I/Pnz6ekpASAp556ik8++YS1a9fSokUL7r77bkaOHAnAc889x/vvv09BQQEbNmzgqquuonXr1tx0002sWbOGyspKWrVqxXXXXceCBQvYsGEDHTp04M9//jNnnXVW8Jx27tzJk08+yapVq0hOTqZv375s27aNH3/8EZvNRvv27Zk9e/YRX8v6bNmyhZdeeok1a9bgdDpxuVz079+fiRMnkpaWBkBpaSnPPfccX3/9NRDo2vP5fHTt2pW///3vREREsGbNGl566SW2bt1KXFwcAHFxcVxyySVce+21DVJrKCgshYDJbMGW0AJP3j48BQcUlkSkURiGwQMvLmNzRkHIaujePpF/TBrU4Ld9X3755bRq1SrY7TRjxgxmzpxJ69atufnmmwH45ptv6N+/P/fffz8AL774IlOnTmX9+vV89tlnJCcnc+211xIREcEf//jHGsd/8sknMQyDjz76CICysjLeeOMNXn31VSZPnsz999/PmWeeSVJSEnfddRdWq5UXX3yxxjFee+01rr/+er777jv2799Pu3btmDFjBn/729+YOXMmd911FwsXLsRut1NVVcVNN93EgQMHGDRoEK+++ipbt27lV7/6FQDJyckNFpTWr1/P9ddfj8vl4qmnnmLs2LHMmDGDRx99lEWLFvHOO+/QrVs3Hn30UT799FNGjx7NM888A8CGDRu45ppreOihh/B6vdx8881UVFTw2muvMWjQIPx+P5MnT2bJkiUndVjS3XAhYksMTM/uKcgMcSUiIqeeiy66iDZt2mAymZg8eTIDBw7k/vvv54477ghuc/HFFwNQVFTEN998c1THv+SSSwCC3XRVVVVs3LjxiPePjIwMjrOqPkZubi4ZGRkAfPbZZxw4cAAIjMcymUx069aNDh06HFWdR+LZZ5/F5XIBMGLEiBr/r6ioYMqUKQBs3rwZgE2bNvHNN99QWVlJ7969eeaZZ4iOjiYjI4OKigoAvvzyS7Zv347JZOKWW27h+uuvb/C6G5NalkLEltgSAE/BgRBXIiJNhclk4h+TBp1U3XDHqn379sHlxMREIPBojBdeeIEffviBiooKrNaDvwKru++OVPU4pEOPcTQPLI6Pjw9eh7qOsWPHjlrv9fPlhrJ+/XoAHA4HUVFRwMFrdujr5557Ltu3b2fnzp389re/xWazMWDAAP7v//4Pu91OWloaLVq0ICsri/fff5/333+f5s2bM3z4cG6//fYGr7sxKSyFiFqWRCQUTCYTTsep/6P/57fHV1VVccMNN5CTk8OFF17I1KlTyc7OZujQoUCgi/Jo1BX4juYYhwuMR1tHQ/il8Fr9+gMPPEDnzp2ZPXs2a9eupaqqiqVLl7Js2TJmzpxJ3759mTVrFm+88QaLFi0iPT2d3NxcZs6cyYoVK/jiiy8a43ROCHXDhcjBliWFJRGRE23Hjh3Bp9RfcMEF2Gw2/H5/iKs6vE6dOgWXCwsL61w+XldffTUAffr0AcDlclFeXg5AQcHBcW3Vr7/++uuMHDmSN954g++++467774bCAS8devWkZ2dzbx587jvvvuYM2cOixcv5owzzgBg165dDVp7Y1NYChFLVOAuAX9laYgrERE59aWkpAS7u6q7uI52nFJjuvTSS2nZMvBH9cKFCzEMg23btrFr164Ge4/vv/8egLvvvjs48eZXX30FwLx584DA2Ko777wTCIyjevnll/H5fDgcDrp27QoEWp769OlDQUEBTz/9NBs2bAAC17xFixZAoFv0ZJ5CwWSEos2vHrNnz2by5MlkZWUBsHXr1iPab+fOnUyZMoU1a9Zgt9ux2WxceumlTJgwAbvdfky1VDfPLliw4Jj2r4+3JJ89UyeAyUyHP76vh12KSIOqqqpi165ddOjQ4ZSYsXnVqlX87W9/qzWD99ixY7ntttuYP38+TzzxRHDsUUpKCr169WLatGnBY3zwwQdMmzaN4uJizj//fAYMGMBf/vIXIDBG56qrriI5OTk4dQBAq1atePDBB1m0aFGNqQO6devGk08+yaRJk2q85y233EJeXl5w6oDqOv/xj38wderU4NQBNpuNgQMHcs011/CXv/yl1vuNGDGCnTt38sQTT7B69WqSkpLo06cP6enpbN68mTZt2jB//vzDXq9HHnmEr776KtiaExERQWxsbI1tsrOzg79jq6cOWL16NREREbhcLs466ywmTZoUnDrgueeeY8mSJZSXl2MymcjLy6Njx47ceOONXHLJJWRnZ/PXv/6VHTt24HA4KCoqwjAMzjzzTO69917atm17rN/+OtX3GW/o399hE5YKCwuZNGkSZrOZbdu2BQe5HUlYSk9PZ/z48ZSUlPDBBx/Qu3dv/vKXv/Duu+9y4YUX8vLLLx9TTScyLPldlWT88zoA2t8/E7Pt6KfTFxE5nFMtLDVFa9asoW/fvjX+mL700kvZtm0bAwcO5I033ghdcWGgMcNS2HTDVVRUcMMNN/D2228HR+MfqcmTJ1NSUkJKSkpwYrHq2x6r/xoINyb7wXDkd1WGsBIREQlH9913H59//nnw69WrV7Njxw6sVisTJkwIYWVNT9jcEtGqVStatWp11PtVVlayZMkSAJKSkoLrmzVrFlyeO3cuw4YNq3P/6vRZl8zMTFJTU4+6piNhMpkx2Z0Y7ioMdyUQf0LeR0RETk6jRo3iX//6F9OnT8fr9eL3+xk1ahS33HILPXr0CHV5TUrYhKVjlZGRgc8XmDPk0Ga4iIiI4HJ6enqj13UkzPZIfO4q/G61LImISE33339/cLZxCa2TPixV3+YIYLEcfCCt2Wyuc5ufq68/s75Wp4ZgdjjxlakbTkREJJyFzZilY3Xo+KbqFiagxvwZRzsGqrGY7YHWL7UsiYiIhK+TPiy1a9cu2KJUVVUVXF9ZeTCAVN/2GG5MP4UlQ2FJREQkbJ10Yen555/nqquuYvXq1UBgwqxBgwYBkJ+fH9zu0NlHR40a1bhFHiGz46eWJXXDiYiIhK2TKiwVFhYyffp01q9fz6uvvhpcf//99xMdHU1WVlbwqc/VY5EGDx582DvhQk3dcCIiIuEvrAZ4X3HFFVRVVQWf3wMwevRoAN5++20SEhIYOXIky5cv57LLLgtu06lTJ95//32mTJnCbbfdhsPhwGq1MnHiRG699dawnR07GJbUsiQiIhK2wioszZo16xe3eeGFF+pcn5aWdtjXwpXJoZYlERGRcHdSdcOdaqpblgy1LImI1KmwsJDRo0fTtWvX4H8XXXRR8FlqABs2bGD06NF069aNiy66qMbNPj+XnZ1d43gPPvhg8LX09HSGDBnC6NGja4yB/bk//elPnHXWWcFjHK2SkhKmTp3K1KlT+fbbb2u85nK5uO666xgwYACrVq066mMfryeffJIhQ4YEz+2ss85i9OjR9V7TpkBhKYTMalkSEalXQkICs2fP5qyzzgquu+uuu0hJSQl+3bt3bx5//HE6dOjA3Llz630WXkpKCrNnz67ztcWLF7N//362b98evImoLo899thxzcNXUlLCiy++yIsvvsh3331X47Xt27ezatUqCgsL+eKLL475PY7VH//4R5588sng10OHDmX27NlN/vmCCkshpAHeIiJH5uqrrw4uv/vuu7Vef+eddxg/fvxxvccll1zCoEGDGD58OOedd95xHetYde/enSuvvJK+ffvWOGcJrbAas9TUmDR1gIg0MsMwMDyukL2/yeY4pptuhg8fTlJSEnl5eSxfvpzdu3fTrl07AIqKili0aBE33ngjt912G7t27cJisZCdnU3r1q25/PLL+c1vflPv8efPn88TTzzB/v37Afjiiy+4/PLLAcjJyeGJJ55g6dKlREVFcdppp1FRUVHrGLt37+bJJ5+s9/3XrVvHAw88ENxn5syZfPnll/Tt25eJEydy0003sX37dgBeffVVnnrqqRo1vvnmm2zfvp2IiAgsFgtDhw5l4sSJxMbGsmHDBu677z4yMjIAGDduHB6Ph9WrV1NYWMigQYN49NFHiY2NPerrfzhbtmzhpZdeYs2aNTidTlwuF/3792fixInBOQ5LS0t57rnn+PrrrwGIjY3F5/PRtWtX/v73vxMREcGaNWt46aWX2Lp1K3FxcQDExcVxySWXcO211zZYvcdKYSmEzJqUUkQakWEYHHjrYVz7toasBkfrbrS84bGjDkx2u50rrriCl19+GcMwePfdd4Oh43//+x/Dhw+noKCAnTt3MmvWLGJjY0lPT+fyyy/niSeewOFw1NvyNGzYMGJiYrjhhhtqrDcMg4kTJ7Jhwwa6dOnChx9+SFFRESNHjqx1jP379//i+59++um89tprwW68a665ht///vfBY8yePbvOcVBvvfUWjz/+ODabjdmzZ9O+fXvuuOMO3njjDZYuXcoHH3xA7969axz7m2++4eOPP8ZqtTJkyBDmzp1LSkoKf/zjH4/q2h/O+vXruf7663G5XDz11FOMHTuWGTNm8Oijj7Jo0SLeeecdunXrxqOPPsqnn37K6NGjeeaZZ4DAOLNrrrmGhx56CK/Xy80330xFRQWvvfYagwYNwu/3M3nyZJYsWRIWYUndcCFSXObC7Q9cfsPrDnE1ItJ0hOdUKkfiqquuCj7383//+x8ulwvDMHjvvfe45pprOOOMM5gxY0aw5SQtLY1u3boB8Pnnnx/Te65cuZINGzYAMGjQIOx2O8nJyZx55pm1tj0R7w+Bp1M899xzAHTp0oX27dsDBANbeno6H3zwQa39Bg8eTExMDBEREcFWuIYcNP7ss8/icgVaKUeMGFHj/xUVFUyZMgWAzZs3A7Bp0ya++eYbKisr6d27N8888wzR0dFkZGQEW+q+/PJLtm/fjslk4pZbbuH6669vsHqPh1qWQsDj9XPrk/PpEVPMdYDh9YS6JBFpAkwmEy1veOyk7IYDaNWqFeeffz6LFi2iqKiIuXPnkpSURHx8PD169MDj8fDJJ5+wYMEC8vLyiIiIYO/evQAcOHDgmN6zuksMAoPN61quZrVaG/z9AbZt2xYME4mJicH1hy6vW7eu1n6H1miz2YBAl2VDWb9+PQAOhyP4DNZDa6p+/dxzz2X79u3s3LmT3/72t9hsNgYMGMD//d//YbfbSUtLo0WLFmRlZfH+++/z/vvv07x5c4YPH87tt9/eYPUeD4WlEPH4DPYXuCEODJ831OWISBNhMpkw2U/eO5uuvvpqFi1aBAQGejdr1iw4EHry5Mm8+eabREZG8tFHH9G+fXuuv/56vvvuOwzDOOG1naj3P5JwWdc2J3pC5l86fvXrDzzwAJ07d2b27NmsXbuWqqoqli5dyrJly5g5cyZ9+/Zl1qxZvPHGGyxatIj09HRyc3OZOXMmK1asCMldgT+nbrgQsFnN9GifiMcIPABY3XAiIkfmvPPOo02bNgCsXbuWtWvXctFFFwGwYsUKoGZXlc/nO67369y5c3D50FaZwsLCWtse6ftXdyUeKjs7u8YD4H9eQ2RkJFDzuaeHLvfp06ees2hY1eG0+j1dLhfl5eWHren1119n5MiRvPHGG3z33XfcfffdQGA82Lp168jOzmbevHncd999zJkzh8WLF3PGGWcAsGvXrjqvdWNTWAqR3p2T8P50+dWyJCJyZMxmM+PGjQt+/atf/QqHwwFAy5YtAdi3bx9VVVXk5eWxbdu243q/AQMG0Lt3bwCWLl2K2+0mNzeX77//vta2R/r+SUlJwW6x4uJifD4f48aNq9Hldyin0xkMGNu2bQve7TZv3jwg8Mivq6666rjO82hUn/vdd98dvPZfffVVjZoiIyO58847Afjss894+eWX8fl8OByO4AB2k8lEnz59KCgo4Omnnw6ODUtJSaFFixYAtG/fvs4uz8ZmMhqjbfIkVX1HQfVDeRvS5l0F/H3aVzyWEBiU1+GhWWH7DDsROflUVVWxa9cuOnTocMpNKFhQUMD555+Px+Nh3rx5wZam9PR0Hn74YTZv3kzXrl0ZPnw48+bNY/369dhsNtq3b89rr71W4/b82NhYLrzwQkaMGFFj6oCUlJTgAOPDTR1Q3ZLUuXNnXnvtNcrKyn7x/asnxHzzzTd59dVXKS4upl27dpx55pn87ne/q7O2p59+GggEkTfffJMdO3Yc0dQBiYmJ/OEPf2Djxo3Mnj2bysrKYB2ffPIJFoul1rV95JFH+Oqrr4KtOREREbWmGsjOzmbr1sAdldVTB6xevZqIiAhcLhdnnXUWkyZNCk4d8Nxzz7FkyRLKy8sxmUzk5eXRsWNHbrzxRi655BKys7P561//yo4dO3A4HBQVFWEYBmeeeSb33nsvbdu2rfNzUN9nvKF/fyss1eNEhqX84kp+9/fZPJUQmFytw4PvYrLYGvx9RKRpOpXDkgg0blhSN1yIxEY58BoHL7/hVVeciIhIOFJYChGb1Ywz4mAS1iBvERGR8KSwFEJxMc5g65IGeYuIiIQnhaUQiot2HLwjTi1LIiIiYUlhKYTiox14q+da8mkWbxFpeLqHR05VjfnZVlgKofgYB16qJ6ZUN5yINJzqeXyqH5Mhcqqp/mxXf9ZPJD3uJITioh2HjFlSN5yINByLxUJ8fDw5OTlAYJJAzeUmpwLDMKioqCAnJ4f4+Pg654tqaApLIRQf4zjkkSfqhhORhlU9C3J1YBI5lcTHxwc/4yeawlIIxUfbcVd3w+luOBFpYCaTidTUVJKTk/F49AeZnDpsNlujtChVU1gKoZhIO9l6mK6InGAWi6VRf7GInGo0wDuEnHarHqYrIiIS5hSWQshhtxycOkAtSyIiImFJYSmEnHYrHjTAW0REJJwpLIWQ02EJTh3g0+BLERGRsKSwFEJOuyU4KaXb5QpxNSIiIlIXhaUQslrM+H4KS163wpKIiEg4UlgKIZPJhGEOzN6gsCQiIhKeFJZCzRJ4po3XrbvhREREwpHCUohVtyxpgLeIiEh4UlgKMZM10LLkU8uSiIhIWFJYCjHTT91wfk1KKSIiEpYUlkKsumXJr0kpRUREwpLCUoiZrWpZEhERCWcKSyFmsdkBPe5EREQkXCkshVh1yxI+hSUREZFwpLAUYla7AwDD5w1xJSIiIlIXhaUQs9gD3XAoLImIiIQlhaUQq25ZMvnVDSciIhKOFJZCzPZTy5LJr5YlERGRcKSwFGI2RyAsmQ2FJRERkXCksBRiNocTALPhC3ElIiIiUheFpRCr7oazqGVJREQkLCkshZi1OiyhliUREZFwpLAUYtV3w1nwYxj+EFcjIiIiP6ewFGJ2hyO4rIkpRUREwo/CUohZDw1Lej6ciIhI2FFYCjH7T1MHgMKSiIhIOFJYCjG7zYLHCHwbDJ87xNWIiIjIzykshZjNasZjWAAwPGpZEhERCTcKSyFmt1rwEQhLHo9alkRERMKNwlKI2W0HW5Y8Va4QVyMiIiI/p7AUYlaLGe9P3waPW2FJREQk3CgshZjJZDrYDedSWBIREQk31lAXcKidO3cyZcoU1qxZg91ux2azcemllzJhwgTsdvth9ysrK+P1119n3rx5FBcXExERgcfj4cwzz+Smm26iW7dujXgWR8/307fBqzFLIiIiYSdsWpbS09MZN24cX3zxBS+99BILFy5kwIABTJ06lTvuuKPefe+55x6mTZvGtm3beOWVV/jyyy/p0aMHn376KePHj2fv3r2NdBbHxmcKtCx5XQpLIiIi4SZswtLkyZMpKSkhJSWF3r17AzBixAgAFi1axPz58w+77w8//BBcTktLA6Bjx44AVFZWsnTp0hNVdoPwmwItSz61LImIiISdsAhLlZWVLFmyBICkpKTg+mbNmgWX586de9j9r7rqquDypk2b8Pv9bNmyJbiuVatWDVlug/P/1LKksCQiIhJ+wmLMUkZGBj6fDwCn0xlcHxEREVxOT08/7P533nknqamp/OMf/+Caa64hLi6O/Px8HA4H119/Peeff/5h9x06dOhhX8vMzCQ1NfVoTuWY+M1W8IPPrbAkIiISbsIiLJWXlweXLRZLcNlsNte5zc+9/vrrPP3001itVj777DM6dOjAQw89RHp6erBLL5wZ1WFJLUsiIiJhJyzCUlRUVHC5uoUJwO/317nNoYqLi3nuuecwDIOePXsGxypddNFF3HLLLdxxxx1MmTKFUaNG1bn/ggULDltXfa1ODckwB74Nfq/CkoiISLgJizFL7dq1C7YoVVVVBddXVlYGl6sHbv9cRkYG7p+6r6Kjo4PrY2Njg8uff/55g9bb4MzVA7z1bDgREZFwExZhKTIykkGDBgGQn58fXF9QUBBcrm4Zev7557nqqqtYvXo1UHMQ+KFddaWlpSe05oZkmG2B/3sVlkRERMJNWIQlgPvvv5/o6GiysrLYuHEjcLCLbPDgwQwbNozCwkKmT5/O+vXrefXVVwFo3bo1F110ERC4Ey47O7vGvmazucbdcmHJEmhZMnwKSyIiIuEmLMYsAXTq1In333+fKVOmcNttt+FwOLBarUycOJFbb70Vk8lEQkICI0eOZPny5Vx22WXBfSdPnsyAAQP43//+x9VXXw0EuvMuvPBC/u///o+zzz47VKd1ZCyBliW/WpZERETCTtiEJQiMS3rhhRfq3aau1202G+PHj2f8+PEnqrQTyvRTWEItSyIiImEnbLrhmjKT9afMqpYlERGRsKOwFA4sgYcEG35viAsRERGRn1NYCgNma6AbzqRuOBERkbCjsBQGzLafxiypZUlERCTsKCyFAbM10A1n8qtlSUREJNwoLIWBYDec3/cLW4qIiEhjU1gKAxabAwCTuuFERETCjsJSGLDYAy1LZkNhSUREJNwoLIUBqy0wZklhSUREJPwoLIUBiz0QliyGxiyJiIiEG4WlMKCWJRERkfClsBQGbA4nABbUsiQiIhJuFJbCgPWnbjiruuFERETCjsJSGLA5AlMHmE0GhuZaEhERCSsKS2GgOiwBGF7N4i0iIhJOFJbCgM1hDy4bepiuiIhIWFFYCgMOux2fYQLA73GHuBoRERE5lMJSGLDbzHixAOBxKSyJiIiEE4WlMGCzWvAagW+Fx+0KcTUiIiJyKIWlMGC1mIItS25XVYirERERkUMpLIUBk8mE76ew5FU3nIiISFhRWAoT1WFJ3XAiIiLhRWEpTPhMP7UsudWyJCIiEk4UlsKED2vg/wpLIiIiYUVhKUz4TYGwpJYlERGR8KKwFCb85p+64TQppYiISFhRWAoTxk8tS5rBW0REJLwoLIUJv/mnMUtehSUREZFworAUJgxzdcuSHqQrIiISThSWwkQwLKllSUREJKwoLIULiw1Qy5KIiEi4UVgKF5ZAy5LhU1gSEREJJwpL4eKnliXDq7AkIiISThSWwoQp2LLkDXElIiIiciiFpTBhstgDCz4N8BYREQknCkthwmQNdMOhliUREZGworAUJkw2R+D/alkSEREJKwpLYcKssCQiIhKWFJbChMUeCEtmv+6GExERCScKS2HCqrAkIiISlhSWwoTV4QTAorAkIiISVhSWwkR1WDIbuhtOREQknCgshQmbMwIAq6GWJRERkXCisBQm7M5Ay5JVLUsiIiJhRWEpTNirW5bwYhhGiKsRERGRagpLYcIR8dOYJRMYPnXFiYiIhAuFpTDhiIgILvvdrhBWIiIiIodSWAoTzggHPsMEgKeqKsTViIiISDWFpTBht1nwYAXAVVUZ4mpERESkmsJSmLBazLgNCwCuCoUlERGRcKGwFEa8P7UsudWyJCIiEjYUlsKI1xQISxqzJCIiEj4UlsKIz2QDFJZERETCicJSGAmGJZe64URERMKFwlIY8ZsDYcnr0jxLIiIi4cIa6gIOtXPnTqZMmcKaNWuw2+3YbDYuvfRSJkyYgN1ur3dfv9/Pe++9x0cffURWVhaxsbFUVFTQoUMH/vSnP9GhQ4dGOotj5zdbwQc+t7rhREREwkXYtCylp6czbtw4vvjiC1566SUWLlzIgAEDmDp1Knfccccv7n/PPffw17/+lXPPPZfFixcze/Zs/vvf/7Jv3z7y8/Mb4QyOn2EJBEKf2x3iSkRERKRa2ISlyZMnU1JSQkpKCr179wZgxIgRACxatIj58+cfdt85c+YwZ84c4uPjmThxIiZTYCbsli1b8uWXX9KvX78TfwINoDos+T3qhhMREQkXYRGWKisrWbJkCQBJSUnB9c2aNQsuz50797D7f/zxxwDExsbyzDPPMH78eIYMGcKkSZPYsmXLiSn6RLAExiwpLImIiISPsBizlJGRgc/nA8DpdAbXRxzycNn09PTD7r9p0yYA9uzZQ0JCAu+88w5/+9vfeOedd1i+fDlz584lJSWlzn2HDh162ONmZmaSmpp6VOdyXKyBliVDYUlERCRshEXLUnl5eXDZYrEEl81mc53b/FxRUVFwecyYMZhMJi699NLgfv/+978bsNoTyPZTOPRogLeIiEi4CIuWpaioqOBydQsTBO5wq2ubn7NYLHg8HuBgN96h3Xlbt2497L4LFiw47Gv1tTqdEPZAWDJ5Nc+SiIhIuAiLlqV27doFW5SqDpm9urLyYGhIS0s77P5t2rSpta56kPfPjxnOLM5AIDR7FJZERETCRViEpcjISAYNGgRQ4zb/goKC4PKoUaMAeP7557nqqqtYvXp18LULL7wwuFxYWFhr3x49epyYwhtYdViy+E6OcCciItIUhEVYArj//vuJjo4mKyuLjRs3Age7yAYPHsywYcMoLCxk+vTprF+/nldffTW470033UTr1q0BmDdvHkBwqoHo6Gh++9vfNuapHDNbZDQAVoUlERGRsNGgY5ZKS0vZt28faWlpvzjj9s916tSJ999/nylTpnDbbbfhcDiwWq1MnDiRW2+9FZPJREJCAiNHjmT58uVcdtllwX3j4+N57733mDp1Kq+88gr//ve/KS8vZ/jw4dx55520a9euIU/zhLH/FJZsft0NJyIiEi6OOSzNnz+ft956i5EjR3LttdeyYcMGbrrpJsrKykhOTuY///kPHTt2PKpjpqWl8cILL9S7zeFeT0pK4m9/+9tRvV+4cUTFAGBHYUlERCRcHHM33KxZs+jevTsjR44E4OmnnyYqKooXXniBESNG8PzzzzdUjU2GMzoQlqz48Xv1yBMREZFwcMwtS5mZmUyfPh2TyUR2djarV6/m8ccfZ/jw4QwdOpQxY8Y0ZJ1NgjMmiioDzCbwV5Vjjj66rkwRERFpeMfcsmSxWIK358+fPx+n08lFF10UOKjZjNUaFlM4nVQinXaqjMAjT3xVh5+EU0RERBrPMYclk8nEnj17cLvdzJw5kyFDhhAZGQlASUlJcJJIOXIRDiuVRqA1qaqsLMTViIiICBxHN9yNN97IJZdcgtPppLKykn/84x8ALFy4kFdeeYVevXo1WJFNhdNuocqwA+VUlZUQF+qCRERE5NjD0qWXXkpqaiobNmzgrLPO4rTTTgOgoqKCQYMGMWzYsAYrsqkwmUy4TA4AXOVqWRIREQkHxzWwqF+/fvTr16/GutGjRx9XQU2dxxzohnMrLImIiISFYw5LhYWF7NixgxYtWtCmTRs8Hg/Tp09ny5YtnHvuuVx77bUNWWeT4TU7wQBPhcKSiIhIODjmAd7//ve/ufPOO4PPaJs2bRovvfQS+/btY8qUKbz11lsNVmRT4rEEBsn7KkpDXImIiIjAcYSlFStWMHPmTMaOHYvX6+Xdd99l7NixfPrpp8yaNYv//e9/DVlnk+GxBR554q8oCm0hIiIiAhzn1AHt27cHYPXq1RQXF3PDDTcA0LZt2wYpriny2mMBMCksiYiIhIVjDkterze4PHv2bDp06ED37t2D6wzDOL7Kmii/MxCWzK6SEFciIiIicBwDvLt3787DDz9M27Zt+eSTT7jrrruCr82ZMyc4QaUcHVNkPABWt8KSiIhIODjmlqX77ruPAwcO8PLLL3Peeedx/fXXA3D33Xdz9913M2LEiAYrsimxxSYG/u+twPBpFnQREZFQO+aWpaSkJP7zn//UWv/ss8/y7LPPHldRTVlkbDxew4zV5MdXVoQ1rnmoSxIREWnSjrll6VC7d+9m7dq17N69uyEO16TFRjso9TsB8JYVhrgaEREROa4ZvBcvXszjjz/O3r17g+vatm3Lww8/zODBg4+7uKYoNspOoRFJAhX4FJZERERC7phbllauXMntt9+O0+nkyiuvZMKECVx55ZU4HA5uv/12vv3224ass8mIjbJT4o8AwFuqsCQiIhJqx9yyNG3aNB566KE6H2vyzjvvMHXqVM4+++zjKq4pio1yUOAPTEzpLc4JcTUiIiJyzC1LWVlZh33+29VXX01WVtYxF9WUxUTZyPcFwlJVfmaIqxEREZFjDks+n6/e1/1+/7Eeuklz2q2UmOMAcBdmh7gaEREROeawlJaWxnPPPVcrNPl8PqZMmUJaWtpxF9dUuZyBuZb8xTmaCV1ERCTEjnnM0p133sl1113HrFmz6NGjB3FxcRQXF7N582bKysqYOXNmQ9bZpPgim0ElmDyV+CvLsETGhLokERGRJuuYW5ZOO+003n77bTp27Mg333zD7Nmz+eabb+jYsSP//e9/6dGjR0PW2aRERUVS9NMdcZ4idcWJiIiE0nFNStmrVy/efvttvv/+exYvXsx3331Hq1atmDFjBg899FBD1djkxMU4yPcFWpO8hRooLyIiEkrHNSllNafTidPpxO/3079/fwCefvrphjh0k5SSEEmuP4Y0cvAUHAh1OSIiIk1agzzuJHgws5mxY8cyduxYIiIiGvLQTUqLZpHk+AJ3xHnyFZZERERCqUHD0qFMJtOJOvQpL6VZFLm+WADcCksiIiIhdcLCkhy7lMRIsn8KS56C/Zo+QEREJISOKiw9++yzJ6oOOUSzuAiKTLH4DROGu0oP1BUREQmhoxrgvXDhQq6++uojaun4pRm+5fAsZhOJCTHke6JpbinFk78fa0xiqMsSERFpko4qLO3YsYMhQ4acqFrkEKnNosjaH0dzSynu3L1EtO8V6pJERESapKMKS0lJSYwfP/4XtzMMg7fffvuYixJonxrLgT0J9GIf7uyMUJcjIiLSZB11WJo0adIRbfvRRx8dU0ES0KFVHAu8CQC4c3aHuBoREZGm66gGeL/33ntHvO2cOXOOuhg5qGPLWPb7AuOU3Ll7MPwaAyYiIhIKRxWWHA7HEW/rdDqPuhg5qFXzaErMsbgNC4bXjUePPREREQkJzbMUpiwWM+1axrPf91NXXNbOEFckIiLSNCkshbEOLePY400CoOrAjhBXIyIi0jQpLIWxjq0OhiXXge0hrkZERKRpUlgKYx1bxrH7p7DkztqF4fOGuCIREZGmR2EpjLVPjSXfiKHCb8fwunHn7g11SSIiIk2OwlIYczqspCbFHBzknZMR2oJERESaIIWlMNexVVxwviWXZvIWERFpdApLYa5Dy1j2V8/krbAkIiLS6BSWwlxaq0PmWsrOwDCMEFckIiLStCgshbkOrWLJ8sXjM0z4q8rwleaHuiQREZEmRWEpzCXEOImNiSTbFweAK2tXiCsSERFpWhSWTgJprePZV/1Q3ZzdIa5GRESkaVFYOgl0ah3PgeC4JbUsiYiINCaFpZNAp9Zx7Pdq+gAREZFQUFg6CXRqc/COOG9hFn5XZYgrEhERaToUlk4CibFObNFxFPkjAXDnatySiIhIY1FYOgmYTCY6tY4PTk7pysoIbUEiIiJNiMLSSSKt9cHHnugZcSIiIo1HYekkcWjLkh57IiIi0nisoS7gUDt37mTKlCmsWbMGu92OzWbj0ksvZcKECdjt9iM6RlZWFhdffDHl5eUALFiwgNatW5/IshtFp9bxBx+om5OB4fNgsthCXJWIiMipL2xaltLT0xk3bhxffPEFL730EgsXLmTAgAFMnTqVO+6444iP85e//CUYlE4lzeKcuCObUeZ3gNejmbxFREQaSdiEpcmTJ1NSUkJKSgq9e/cGYMSIEQAsWrSI+fPn/+IxZs+eza5du+jTp88JrTUUTCYTaa0T2OlNBqBqz6YQVyQiItI0hEVYqqysZMmSJQAkJSUF1zdr1iy4PHfu3HqPUVBQwBNPPMGjjz6Kw+E4MYWGWKfW8aR7UwCo2rs5xNWIiIg0DWExZikjIwOfzweA0+kMro+IiAgup6en13uMJ554ggsvvJABAwYwbdq0I37voUOHHva1zMxMUlNTj/hYJ1qn1nGs9PzUsrR3C4bhx2QKi7wrIiJyygqLsHToGCOLxRJcNpvNdW7zc4sXL2blypXMmTPnxBQYJqofqOsyrDiqyvDk7sWe3C7UZYmIiJzSwiIsRUVFBZerW5gA/H5/ndscqqysjL/+9a88/PDDxMbGHvV7L1iw4LCv1dfqFArN4yOIjnKS4W1OV1smlXs2KyyJiIicYGHRh9OuXbtgi1JVVVVwfWXlwWegpaWl1bnvsmXL8Hg8vPzyy4wZM4YxY8bwww8/BF+fMGECY8aMwe12n6DqG0/1TN7pwa44DfIWERE50cKiZSkyMpJBgwaxePFi8vPzg+sLCgqCy6NGjQLg+eefZ/ny5dx///3069ePUaNGBV+rdv311/Pdd98B8Morr5wS8yxVS2sdx9r0nwZ57/5R45ZEREROsLD5LXv//fcTHR1NVlYWGzduBA52kQ0ePJhhw4ZRWFjI9OnTWb9+Pa+++mooyw2ZTq3j2eVtjhsbvvIi3Nl6qK6IiMiJFDZhqVOnTrz//vuMHDmS2267jSFDhrB06VImTpzIiy++iMlkIiEhgZEjRxITE8Nll11W6xhfffUVo0ePDoYtgJtuuol77rmnMU/lhOrSNgEfFra7A61LlTvXhrgiERGRU5vJMAwj1EWEq+oB3vUNAg+Fmx+fR+fy77ky6juc7XrS8rpHQ12SiIhI2Gjo399h07IkR65nx2Zs9rQCoGrvVvyuyl/YQ0RERI6VwtJJ6LSOzcj3x1BsjgO/l8rdP/zyTiIiInJMFJZOQj3TAo+B2VgZmF28Ml3jlkRERE4UhaWTUGqzKBJjHfzobglA+Y41aOiZiIjIiaGwdBIymUz07JjEdk8LfGYbvpI83Nm7Ql2WiIjIKUlh6STVs2MzPFjZaw087qR826oQVyQiInJqUlg6SZ3WMTBuaWVxCwAqFJZEREROCIWlk1SblBhiIu1sqGqJYTLhzt6Fpzgn1GWJiIicchSWTlJms4meHRMpN5yURbcHoGLb6tAWJSIicgpSWDqJ9eyYBMBWIzBuqWLbd6EsR0RE5JSksHQSqx639HVuIDRV7tmEr6o8lCWJiIicchSWTmIdWsYS4bCytzIS4luC30fFdnXFiYiINCSFpZOYxWKme4dEALLjegJQvPJTDMMfyrJEREROKQpLJ7nqrrhF5V0wOSJx52RQvmVliKsSERE5dSgsneQGnBZ4Ptx3O8qI6HsxAIWL38Xw+0JZloiIyClDYekk1yYlhvapsfj8BhsdfTFHROPJ30/55uWhLk1EROSUoLB0Cji3T+CBuqu2FxN31iUAFK+aE8qSREREThkKS6eAvl2TAdiwPZeo04eD2Ypr/zYqdqwJcWUiIiInP4WlU0Ba63iinFbKq7xkFELsGcMAyP7oObwleSGuTkRE5OSmsHQKsJhN9O7cHIA1W3JoNvxGHC07Y7gr1R0nIiJynBSWThFn92wBwOLv94LZSvy5vwagdN18fOXFoSxNRETkpKawdIoY2CsVu83C/txytu0pJLLzmdiSWuOvKifz3ccxfJ5QlygiInJSUlg6RUQ6bZzTOzDn0rvztmEymWlx5QOYI2JwZ6VTun5RiCsUERE5OSksnUKuHt4Vq8XE6s3ZrN+eiy2xJQmDrgAgb+6/yPvyNQzDCHGVIiIiJxeFpVNIy+bRjDi7HQCff7MLgJi+I3C06gJAyeo5lG9ZEbL6RERETkYKS6eYi8/tAMC3P2aRX1yJ2Wqn5Q2PEXtW4FEo+fPewO+uCmWJIiIiJxWFpVNMuxax9OiQiN9vMO+7PQCYzBYSL7wOa1wyvtJ8Cha+rWfHiYiIHCGFpVPQqIHtAfhy5W58/sAYJbPNQbPhNwJQsuYLcj+dGqLqRERETi4KS6egc3u3JCbSRl5RJQtX7Qmuj+p6Ns1HTwSTmbIfl1Kxc30IqxQRETk5KCydguw2C1cMCQzqfuPzTZRXHpxjKabPEGL7jQIgb+7L+F0VIalRRETkZKGwdIq6bHBHWidHU1Lu5osVGTVeSzz/aqxxzfEW5ZD31WuhKVBEROQkobB0irJazPz6wk4AfLo0nbJDWpfMjkiSx9wZ6I7b8DVlm5eHqkwREZGwp7B0Cju/b2uSEyIoKHHx1Jvf1ZiQ0tmmO/HnjAUgb86/8JbkhapMERGRsKawdAqzWS386bdn47BbWL89jzVbcmq8nnDeVThSO+GvKiN71mT8HleIKhUREQlfCkunuA4t47jknMBEle98tQWfzx98zWSxkjz2LswR0bgyd1C4+J1QlSkiIhK2FJaagDHnp+G0W9i2p4ipH6yrcXecLaEFyZfeAUDxt59RuGwWhuE/3KFERESaHIWlJiAx1skfxvcFYMGqvfz13ytqjF+K7Hwm0b2HAFC4+B1Kv58XkjpFRETCkcJSE3Fun5b85eYB2KxmtuwuZMXGzBqvNx/9O+IG/gqAwmUf6PlxIiIiP1FYakL6dU/h8p+mE5g2az27DhQHXzOZzCQOHo81rjm+skIKFv03VGWKiIiEFYWlJubyCzrRqXUcJeVuHp7+Tc3AZLWRdNGtAJSsnktF+tpQlSkiIhI2FJaamEinjb/fdi5d2yZQWuHh9U9/rPl62hnE9rsIgJxPX6AyY2MoyhQREQkbCktNUHSEjfuu7wfAuu25ZBfUfD5c4pDrsSe3x19RQubMRyn7cWkoyhQREQkLCktNVEpiJH06JwHw8v82UOnyBl8z2xy0/M3jRJ82GAw/OZ++iDtnT6hKFRERCSmFpSbsqmFdsFrMrN6czeT/rsbnPzidgNnupPllvyeycz/we8mdPU3zL4mISJOksNSE9e7UnMduOwe71cyqTdnMXb6rxusmk5mki27DZI/AlbmD7PefwlOUHaJqRUREQkNhqYnr2bEZ/3dpTwA+XLgdj7dm65E1JoGEc38NQMWONWTOfFTPkBMRkSZFYUkYcXY7EmMd5BVX8dnS9Fqvx/UfTdzZlwHgLcwi879/wVuc29hlioiIhITCkmC3WbhmZHcA3p67hYzMkhqvm6w2mg37DS3G/wkA14Ht5H35WqPXKSIiEgoKSwLAiLPb0q97Cl6fn2dnrsHj9dXaJjLtDFqMewiAyl3r9UgUERFpEhSWBACTycQdV51ObJSdXQdKmPHFljq3i0jrizUuGcPrpnLnusYtUkREJAQUliQoIdbJpCv7APDhoh1MeXctPl/NAd8mk4morv0ByJ37L6r21h2qREREThUKS1LDwF4tGTe8CyYTzF+1h9c++7HWNvHn/hp7izT8FSUc+O9fyJ37LwyvJwTVioiInHgKS1LLdaO68+ANZwHw2dKd7M6qOeDbEhlLyxv+TlS3AeD3Uvr9VxSvnhOKUkVERE44hSWp0zm9WzKwVyoAH329A8MwarxutjlIvvxe4gaMAaDsBz0/TkRETk0KS3JYYwanAbBg1V6efed7/P6agclkMhE/8FdgtuDO3kXW+0/iLS0MQaUiIiInjsKSHFbPjs24/qLuWMwmvl6zj3e+2lprG0tkbKA7DqjYvpr9r92rCStFROSUYg11AYfauXMnU6ZMYc2aNdjtdmw2G5deeikTJkzAbrcfdr/nn3+elStXUl5eTklJCT6fj/bt2zNu3DhGjx6NyWRqxLM4tVw1rAtJ8U6ee2ct/1u0ndGDOhAX7aixTfKYO6k8fSj5X72OJ28fOZ++QOo1f8FkCauPl4iIyDEJm5al9PR0xo0bxxdffMFLL73EwoULGTBgAFOnTuWOO+6od98PPviAHj168Mknn7B48WLGjx/PqlWruPfee3niiSca6QxOXRee2YZObeJxe/38/fVvKSytORmlyWwhskMfWlz1R0x2J1V7NpE39xUMf+2JLUVERE42YROWJk+eTElJCSkpKfTu3RuAESNGALBo0SLmz59/2H3btWvHpEmTMJsDp3Prrbdis9kAeOedd6ioqDjB1Z/aTCYTV1zYGYCtuwv56ysr8f1s/BKALaEFyZfdCZgoXb+AzBl/xZW5s5GrFRERaVhh0U9SWVnJkiVLAEhKSgqub9asWXB57ty5DBs2rM79Z86cWeNrm81GbGws+fn5eDwePJ7DzwE0dOjQw76WmZlJamrqEZ3Dqe7cPi154IZ+/PO/a9h5oJivVmZw0Tkdam0X1bU/yWPvInf2NKr2bGL/6/cRe9YlNBt+IyZT2GRzERGRIxYWv70yMjLw+QJdNk6nM7g+IiIiuJyenn7ExyspKaGgoACAXr16ERcX10CVNm2D+rTit5f1BOD1z35kX05pndtF9ziX1hOeI7rneQCUrPqc/C9fqzX9gIiIyMkgLFqWysvLg8sWiyW4XN2t9vNtfsmbb76JYRgkJiby+OOP17vtggULDvtafa1OTdUl53bk2x+y2LAjj+kfbuCx286pcwC9LT6F5F/9gYiOp5P72YuUrPmCqr2bSLzweiI79Q1B5SIiIscmLFqWoqKigsvVLUwAfr+/zm3q8/nnn/Pyyy/Tt29fZs2aRdeuXRuuUMFiNnHHuDOwWc1s2JHH1PfX4fYcfiB3TO8LSLrkNjCZcefsIev9JyndsKgRKxYRETk+YRGW2rVrF2xRqqo6eKdVZWVlcDktLa3eY3i9Xp599ln+/Oc/88ADDzBjxgxatWrFjh07cLvdJ6bwJiolMZIrh3YBYN53e5j5Zf0P0409fRhtJ71MdO8LwfCT+9k09rw0kf1vPISn4EBjlCwiInLMwiIsRUZGMmjQIADy8/OD66vHHQGMGjUKCMypdNVVV7F69ergazt27GDcuHFs2bKF2bNnc8MNNwS78CZMmEBOTk5jnEaTMn54F357aWD80mdLd5KRWVLv9tbYZjQfPfGncUwG3sIsXPu3kvv5dHyVZY1QsYiIyLEJizFLAPfffz9r1qwhKyuLjRs30qtXr+B4osGDBzNs2DAKCwuZPn06AK+++ir9+vUDYOzYsbjdbuLj4xk7dmyN45aU1P9LXI6NyWRizOA0Fqzaw+6sUn7/z0V0bZfAn397dq1JKw/dp/llv8eamErRsllg+Knas4ndz/6G2H4XEdNnCI4WHRv5TEREROoXFi1LAJ06deL9999n5MiR3HbbbQwZMoSlS5cyceJEXnzxRUwmEwkJCYwcOZKYmBguu+yy4L7V3WxFRUW1/jt03JM0LLPZxAM3nMXpXZoDgTmYPvp6R737mMwWEgePo+NDHxB75qjg+pLVc9n/2v0ULHkPv7uqniOIiIg0LpOh+7kPq/puuPrumJOApWv38/R/VxPhsPLsHwbTOjnmiPYz/D4qd66nZM0XVOxYA4AtqTWtfvs0ZpsDX1U5ZkekHlkjIiJHrKF/f4dNN5yc3Aad3pKPl8SzbU8Rf3zpG16898LDdscdymS2ENmpL5Gd+lL6wxLyv3wVT94+Mp6+BnNENP7KMpztepIy9h4sUZovS0REGl/YdMPJyc1kMvHITQNokxJNUamLJ99cRU7B0T1mJua0wTS/9PfBr/0/Dfyu2v0je16aSNHy/+GrqHsiTBERkRNF3XD1UDfc0ftxZz4PTlsGQKTTyj/vGEyblCPrkqtWkb4Wv6sCw+fBZLKQ99Vr+CsDIcnsjMbevA1+VwXNL7sDR0p7fBWlmKw2zHbnLxxZRESagob+/a2wVA+FpWOzbP1+3vx8E1n5FSTGOrn/+n707Njsl3c8jKq9m8mf9x9cmTUfeWOyObBExuItzsUSk0jrm/6prjoREVFYakwKS8euuMzFH19axt7sMsxmE/dddyb9uqfgtB/7MDlfeTHlW7/F8Lop/vYzvCV5NV53tOpCwnlX4WjZCZPNgdlqB8BbWkjZpqXE9h2J2fbL46hEROTkprDUiBSWjk+Vy8sfp3/Djr1FAJzepTmPThjYIHe2+SpKyJz5KN7iXBLOH0/+/DfA562xTWTXs0kaeQuZ/30ET8EB4s6+jJgzhlOxdSWu7AyaXzopGKhEROTUobDUiBSWjt/e7FIeeWUFeUWBR9cMPasNw/u3o0eHxOMOTYbhx/B6MNscuLIzKP7uc6r2bsJbmHVE+ze/dBIxvS888vfz+zB8XrVOiYiEOYWlRqSw1HA++noHr3/2Y/Dr4f3bcvsVfbBaGv6GTL+rAld2BgUL3sJ1YHu92yZccC0WZxT21DTMjkg8efvwluaDYRDd8zwskQcHp2e+8xiurHRa3/RPrLHHPgZLREROLM2zJCelsRd0ol1qLIu/38fXa/Yy77s97DxQzIM3nEWLZlEN+l5mRyQRbXvQ6v+eonLPJip2rKF4xcd1blv49YzDHqd883ISzrsKk82OJTqByp1rASj+bjbNhv2mQWsWEZHwpZaleqhl6cT49odMnn93LWWVHmKj7Ey8og8De6We0Fm6i1Z+QtGKj0ke8wes0fFUpK+lav828PvxFGbiydsHZgv25PaYHU6qdv942GNZ45rT+tYpuPZvwzD8OFt2xuyIPGG1i4jI0VE3XCNSWDpx8osreez1b9mxrxiATm3iGTesC/17tMBsbvxHm7iydmKJjAt2rxUufZ/CJe9hiUnEV1pQ774mu5OEQVcSN2AMJpMJw+ehat9WnK27YrLYGqN8ERE5hMJSI1JYOrHcHh/vzd/Gx4vTcXt8ALRJiaFDaizN4iMYfEYrOrWOD0lthmHgK83HEpOItyiHvS9NBCCy05nBZ9iZI2MxW+3BKQwsUfFgtuB3V2K4KnC07EzcgDE4W3XGlZmOvXkbbIkt63gvPyaTJtMXEWkoCkuNSGGpcRSXufhkSTqzl+2i0lXz9v8h/dow6co+2KyWEFUXULzqcyp3bST5V3dSvm0V/qoKYk8fChYrJas+J3/+m2D4f/E41vhkDJ+PyI6nk3TRLVTs+J7cOS8T1+9iYvoMwRwZg7+8GHNUHGarPRC8fD787gpMZhuW6DgFKxGRX6Cw1IgUlhpXWYWb+av2UFrhITOvnGXr91P96fzNJT24Ykjn0BZYD29ZEZ68vWTO+GtwXexZF1Py/Vfg82KyOTA8rhr7mCNigo9x+TmTPQJHi464MtMxPFWH7BONIzWNZiNuxt6sZWD28tikYx7v5SnMomL7amL7jsRkVZehiJwaFJYakcJSaH2z4QDPvfM9Lnegi65v12R6dEikosrL2As6ER8TfvMdVexYQ/68N0i6+FYi2p2GO2c37pw9RPU4h6o9m/CW5OOvKqNg0QwMr7vB3jeq20AcrTpj+HzEnXURZnsEhmHgydsLJjOGuwpLbBLW6Pga++1/4yFc+7cS3ftCEgZdgS2hBYZhULLmCwyfl4h2PbHGp2BxNuwdi6cyd94+KtLXEtdv1BGPWfO7KzHbI05wZdIUGYZxxH9MHc224U5hqREpLIWex+vjjdmb+HTpzhrrk+KcnNk9hZTESH51fids1pOra8pXUYo7JwOT1YYjtRNVezdjT26P4fNgjogm58N/Url3M1Fdz6Zsw6KjOrbJ5sDZuhvu3D34ygoPrrfaiT1zFHEDxuDJ24vZGcX+1+6rsa/ZGYW/qrzmOkckiUOux57SHmtcc6zRCQCUbviash+X0PzS3wfGaxl+TOaD3aXVY7Fc2Rnkzn6JxAuvwRIVT9nGr0k476pT9g7CXU+Nx/B5SBz6G+IHXPaL2xev/oL8L18l5df3EtVtQL3buvP2kTnjb8SfM5a4sy4+7lq9ZYV4Cg4Q0bbncR+rqTC8Hgq+nklkp75EtO8V6nLq5c7bx4G3/0z82ZcRf87Yerf1e1zsf/1+7MntSBl7d83j5O6lePUcEs+/Gktk7GGP4asqJ//LV4k+bTCRaWc0yDkcK4WlRqSwFD627i7g48XpLFt/oNZrZ3RpzrjhXWnRLJJmcYf/69zvN3B7fcf1fLrGYhhGMHwUfvMhhseF312JLT6FuP6jKV71OflfvQ5mK9bYwCD0upnAZDqi8VRHytasJTF9hlKw8G0AYvoMxZ2/D3fWLmL6DCGyU19cmTsp/u4zIjv3w7V/G56CzEA1VnugRc1kJqLj6RieKnxlhbS88SnMzkhK1y3E764kutsArHHNMQw/3sIsrAmpgXMwmXHt24IrO4PYviNqhLOfXz9vSS7W2CTw+U5oF6O/qpzy7auJTOuLJTKGnY//GoCItDNIHf+nX9y/enuAjg9/ePC4HheZ//0LJpud1Gv/islkJvPdx6lM/77Wtkei+kf9oS0He6dPwlOQSYvxf2qwX25+dyW5n08nqvtAorsNPLZjuCow2SPqbeUw/IEWZ5PZgmEYVGVsxN6iA5aImMPuA4FpRCwRMcT0GXJMtRWvmkP+V68Bv/w9cGXtBMPAkZp2TO91vLJmPU3F1m+BX661Yvsast5/AoD2983AbHdiGAauAzvI/uBJfOXFONudRsvr/nbYY+TPf5Pibz/9xffze93gDzyBwWSxYnY0fKuqJqWUJqlru0QeuCGRe31+yio9LN+YyY69RSxcvZe123JZuy0Xkwl6d0ri8gs7c3rn5rWmIJjy3lqWrdvP4787l27tE0N0JkfGZDKBKRAEEs79da3X4866hMjO/bDGJgUDg99dib+qgortqyjd8DV+VzkpV/4RW1xzMJup2PE9Of97BsPnqXEsW/M2RKadQfHKTw+uNFtp87sXsMYkUrTyU4qWf4TJZMLvqsSTfyAYlABK1x/8YVSy5gtK1nwR/Lps4+Ia7xXsejT8wV/6APtevQeLMwp3zu7AcVbPJe6siynduAR3VvpPF8WMyWINHqNi+2qaDbsRe/M2gUMafiq2rcZTcIDKXeup3LUBS3QivooSWlz1IJFpZ1CybgG+0nwwWzHbnbVaZ7xlhZSs/oLITn0x2Rw4UtrXuvaHhg5PcQ77X7sff2UpzrY9a/zVXZm+lgP/fYSUX99H6dp5mGwO4s66BAj8BW62Ow8b9gCKV3wSnIHenbULR2oahrvy4LXdvIKItj2wRMUd9hjVXAd2BFoYzhlLwnlXBa9XdYgtWDQDb3EuztZdsSe3+8Xj1ad45WeUb/qG8k3fEH3IL0xfeTFV+7dhstpw7d9G/DljMVls+D0ust5/EkdKB5oN+w3lW74l+3//JPGCq4k/5/I638PvrmLfv+/CEpVAy988TtkPS8j99AWcbXvS8vpHAShZO5/i7z6jxVV/xJbQgsqMjVTt3x6ciDay69m1upc9RTmUrl9I/IAxNX6BG4afgoVvY4mIxVOUfXC914O3NB9rfEqtYOf3uoMtt+3vffuYW1L9rkpyPptKVNf+xPS64Kj2NVwVR7ytt+zgFCnu3L04W3UO3Lwy7z/B9VW7fzj8e/l9ePL3115vGBhed/AxUYbhZ/+/7wk8KQETtsRUWt00Oey7/xSW5KRisZiJi3Zw0cD2MBBGDWzHi++vZ19OKW6vn/Xb81i/PXArv91qJjbKzogB7amo8rBw9V4AHpy2jH9MGkTXduEdmH6JLT6lxtdmewRmewSxZ44i9sxRtcYfRHU5i+TL7yH7w38S1/8SLNEJFK/4mOYX3YqzTXeiuvTHnbc/8Few4Q8eP+HcXwd/afmryindsJDiFZ/gKy+q+f7OaPxVZcd0Lr6SPHw/TcEA4C3KrvFDGgDDX2OcV+XOdex75Q8ARHTojeHzUrVnU83j/vQLIOvdx7A1a1Xrh3nBwrexxiZhdkYR23cEZZuWU7lzLUXfzAIg+Vd/ILrneRSt+BhPUTYWZzQla+dhi08meezdlKydFxykX7Wn9kSmVbt/5MDbj+DJ3QMExrSZHVGUb/2O6O4DaX7ppBrb7/v3XUR1PxdvSX6NEFqxcx2O1DS8h8z5lfO/f4LFirNNd9w5u4nrdzEYBvGDfl0rhBUsfgfD66ZwyXvEnXUJZmdUjdZId/Yu8ub+C8xW2v7+ZazRCfg9LvyVZVhiEqjctYHc2S/RbMT/YUtIrTNEQiAEeopzg1/vmnwdzYbfiL15OwoWvl3jGhl+P/EDx1C26RuqMjZSlbGRhPOuIvvDpwM1L5qBrVlrCpfNIvnSSdiT2wJQuedHyjctx1uUg7coh8pdG4Lfr6o9PwY/93lzpgOQO3sazUbcVOPmi8C2m4jqclaNdQfe+CO+8iL87kqShv9fcL1r/7bgHxPOtj0OXtdF/6X4u9nEn3sFER16UbphMYnnjwtMIVJ58N9C7ufTcbbpTkTH0/EWZuFo1QVLRDS+yjIsEdG1rqO3tAAMA8Pnofi72VRs/ZaKrd9StOJjEs69guieg/C7KvGW5lOZsZHKnetJHnNHrUB2aLdRxc51OFp2xp2ZjrP9acG7aks3fo2vtABfxcGbTdw5u3G26lz73yBg+Dzkz3sDV9ZOUsf/KfBZKi1g36v34K8oCW7n97gw2xwULnmPom8+JPXav4DJTMWONXgKDvYQuLN34cndG/z+hit1w9VD3XAnD8MwyCms5MNF25m7POOI9vnzTWfTv0eLE1tYGDJ8nuOeLNPw+wI/rIuyKd+yAktMEjG9z+fAm38KdBtd/WcMwyD7/Sep2ru5xr7ONt1rrcNsxRIdHxhQHptE0TeBFon4c6/AEhVH+ZaVRHU7O9D1CET1OBdfWVHtgGIy40hN+8VnAh4pszMKR8tOVO5cX+s1S1Rc4BdMA3ZxHo6zbQ+Sf3U3e164+Re3TR57N1Fd+lO2eTlF33yINT6lRiuevUVaIBBUlNRqZQRIGDyOyLS+HJjxVwx3JdG9zq/VQhjTZyiWqDjsLTriryrD8HmxRieQ88mU47pxwdGy82G/d/aUDkR17U/hkvfqPUbSJb+jeMUnNX4h1yWu/2jizr6MwiXvYo1tTtGKj4K1W6LiSfn1vXiKcvAW5wbC69qvjvxELFbiz76MouX/q/NlR6suRHU9m4KFbxPV/RyaXzoJb1EOhUvexVtaiCsrHXzeOvcFSLjgGopWfFyj5SjhgmtIOPfXlG1egdlqp3zrSkrXL6xzf1tSa/yVZYGpSX66S/fQP3Zi+11E0siba3QRV4vrP5ri72YDgX/LzjbdcWXuoHLXhhrbtbr5GfyucjLffiRwSaLia/2BVS1xyPXED/zVYc/3WGjMUiNSWDo55RVVsj+3jMXf72P99lxyCitpkxJD84QIBvRswf++3kFWfgXxMQ7+cvOAkE182RQYfl/gh6jhp3DpByQMHkdEh9743VXsfuYGAFKv+UuNv3T97koKF79LZOd+tQbQlm/9lsqMH0gcch0mk5n8+W/gd1UEB5hHdT8HZ+uuGD4vu54aF9wvokNvHKlpWKLiKd/2XY3H2diatcSTf/AXa+xZFxPZ6Uyy3vl7necU2fVsPAWZwdaiEynhvHEULq07HBw6QaocPXNENGZnNN7CrEZ8VxM123sCIjufRdWeH/EfRbdZXSI796Ni++rjOkY1c2RsjZaioxUcn3gEItr3IvXavx7ze9VFYakRKSydGsoqPURHHGxJcXl83DtlCRmZgR8E3dsnMuC0VBJiHcRFO0iIcdA2JQaL5eS6w+5k48rOwFuY9Yt3gB2rA2/9iaq9m4npM4TmoyfWeM0w/BQufhdLdCJx/UbhLckjf8FbOFt3I/bMkZjMluC0CpaYZsSeMRx3zm78HhcpV9yH4a4i64OncO3bSkSH3ngKsvAW1x5kH9HxDOL6XYTJ7iTzv4G/sB0tOxPZuR+G1x1sQYNAK1Zc/0sBA8Pnw1dWSNJFt5DzyRTKN68IbhdzxnASBo/DEhXPrqfGgz/QAmGy2Gq0FJkckUR1PRtvcS7u7Axi+42iat9WqjI21nm9onoOovzHZTVXmsz1tpzVN1dYfdtE97qA8s3L6/xlmjj0N7gObKtxzqFksjsx3FW/vOEvSLroVmL7jqDk+68CXZ7HKfHC6yhY9N/jPs7RcKR2wpW5A1tS68DzNBtIVPeBpFx+b4MdDxSWGpXC0qmrtMLNlHfXsmpTFv46/gUkJ0Qw8YrT6dstufGLkwbhLSui7IclxPYdgdnuPOr9PQWZVGZsJLr3BZit9lqvG34fFTu+x5HaCV9ZAXlfvkqzYb/BGpdC2Y9LKN/0DS3GPRwcgF32w1LMkTFEdjw9eIyyzSvI/exFml82iaiuA+oc5OrOP8D+1+/DFp9Myq/vw5rQItgKV7V/GyVrviRxyPVYouLI/O8juHP3kvyrP+Bs0z04qLaar7KM0g2LiDltMOXbVlG6bj62Zq1w5+4h9epHKNv0Dd6ibCp3/4ijZRqRHfqQ/eFknO1Oo9nQGyha8RG2Zq2o2v0jSZfcji2+OYbXGxgobvgpXvU5ZT8sAQJdOdGnDcbZqkuN7pyYM0bQbPiNeAoy8RblkDf3ZfxeD/h9OFt3o8XVf6Ji2yqyZwXGLkV2PZvobgNxtuvJnhduCR7H1rwtYODJ3VvjHG1JrbHGNacyfe1hv7fNRt5M/pev1uoa6vDH99kz9VZ8ZYVEdDydlMvvwWSPwLVvCyZ7BGU/LqV4xcc1ptiwRMWReu3fKNu0jLh+FweDeOm6+TXes83t07AlBLr9y7evpnzLCuLOGs3+/zwIfi/myFja/O5Fcj+ZgresiJbX/43KjB/I/uApINANaY1tRkX6WhIvuIb4gb8i74t/U7p+IdbYJHwVxUT3GBS4weEwgfhQ1oQWWJxRuDLTD167Zi1Jufxeyrd+S9nmFTVbT81WOjz4Dv6KUixRceQvfBtvYRYJg8eTOeMv+MqLD/tecWdfStWeTTXeq1qLax4hom1PTJaGHUKtsNSIFJZOfQUlVXy5IoN9OWUUl7soLnOTXVBOpcuH2WzitI7N8Hj9REfacNgs9OqURHJCJGd2Sw77uzfk5HAkEwH6Kssw2ex1hraax/Jj+Ly/uN3RcOfswdYs9YjGubmydrL/tfuI6Hg6qVf/Obi+YscaCr/5kORLf48tMbXGPr6q8uAvSpPFGhycXpmxkYqd64gf8CsskTHB43gKs4ntd1GNa1aRvhZ78zZ4SwuwJ7fDZLHiztmDr6KE8k3LgmN3ok8bTGSXs4jufg7unD1YYhJx7d9K1ntPkDB4PAnnXUnVvq2U/bCEhPPH15qGwPD7KFnzBY4WaWAykfv5SyQMupLonoNqbFexc12wG9dktRPZtT/JY/5Q5/e5bPMKSr//kmYjb8ae1Lr261tWYE9sFRwAbfh9wWtkGH7w+8FsCR7bV1nK/v88WH/3oslM6jWP4EjthN9TFRiXVZxLZFrfGncBekvyqNq3ldzPp5N82R1Ede1f5+H8Xjd5n08PBmUAS0wibSe9jCd/P7akNoGHjBsG+1+9F3dORnC7dnf9p965m46VwlIjUlhqmqrcXqbNWs/Xaw7fzNwszknHVnFcfE4HBSeRQ3gKs7BExGAOo1nf8xe+jTt7FylXPlhnkPRVlmF2RjbYcxcNn5eM5/4PDIO2k16u8463xlC+9VtsCS0o+3EZUd0G4MrOILrHORh+/1HNyn8kD/uuOrCDA/95AGf7XsT2HUFEhz51voffVYHh9ZDz6RTMjihSLr/nqM/rSCgsNSKFpabLMAw2puexdXchcdEO8our+G5TFjv2FtW5fac28ZzbuyVD+7UhIfbou3xE5NTiLSvE8HmwxTWdrnxPwQEsMc1qdf+GgsJSI1JYkkNV/1PJzC9nb1Ypa7bm1JqmwG4106tTEgN7taRlUhRbdhdgMZu54MzWJCpEiYg0Cs3gLRIi1V1tLZOiaZkUzdmnpTL2/E4UlbrYuqeAucszOJBXzpotOazZUvPOqLfnbqJ9aizxMU76dG5On85JOGwWYqPsREc23PgSERFpeApLIschNSmK1KQoundIZMTZ7Vj5QyZZ+RUsW7+frPwK+nZN/ilMFbJjXzFQzOrN2TWOMbBXKuf1aUWV20v/ni2Iiw59E7aIiByksCTSQCKdNob0C9yxcs3IbjXuctqxr4jMvHLyiipZty2XH9IDj/Zwe/2s2JjJio2BZ3RZzCaSEyI5La0ZToeViioPLZpFYfgN0vcXEx/joEvbBE7r2IyWzUMzaFREpKlRWBI5QQ69Q65T6/jgTOFjL+iE329gMsHyDZlM/996kuIjKK/0kJVfQWZ+OZn55Yc97pcrdxMTaefua/pyRpfmwckzfX6D1z/7ge17irj3ujNJTji2B3eKiEhNCksiIWA2B4LUuX1acm6flgD4/Qb7c8vIKazg+y05lJS7iYt2UFrhZuf+YvbllOL1BQaZl1a4+durK0mMddI6ORq7zcIP6XlUuX0APP3WakYOaIffMCit8NCqeTQDe6XWXYyIiNRLYUkkTJjNJtqkxNAmJYYzu6XUuY3fb1BU5uLfH29k3bZcCkqqKCip/SiGrXsK2bqnsMa6jq3iyC+upFu7RM7qkcIZXZP56tvdfL8lh1vG9KJ7h8QTcl4iIic7TR1QD00dIOHM5fHxQ3oeBcVV5BRWcnqX5nRsFcfmXQW8v2AbFVUerBYzWfnllFbUfrr8oawWM0nxTprHR3LeGa1oFuvEMAwSYp00i3NyILecdqmxxEbpzj0RCX+aOkBEAHDYLHW2QPXtllzrmXY/7sxn/nd7sNnMVFR62ba3kMy8cmIi7ZRWuPH6/GTlV5CVX8HGnwaf/1yk00qfzs0Z1r8tsVF2iktdlFZ42JdTSoTDSsdWcfTrnqLZzEXklKOwJNIE9OzYjJ4dmwW/9vkN9mSV0DYlBrPZxL6cMsoqPGzOKODdeVupdHkxmeDQdueKKm+NO/fq0qFlLJ1ax+M3DMwmE16fn/apcQw+oxUWi4myCg+FpVW0SIzi3Xlb2ZNVyh3jTqdti4Z/NpSISENRN1w91A0nTVFZhRuf3yAu2oFhGOzOKiUuys667bl8vyWHbzYcICbShtNupcLl5cxuyfh8BkvW7sN/jD9N7DYL3dolMPaCTlS6vKzenE2HlrGMGtAep0N/04nI0dHjThqRwpJIbX6/Ebyb71A79xezdXcB2/cW4fX58foM/IZBZl45uw4UYxgQ4bAQE2knp7ASs9mE/xfSVWyUndHndsBkNvHjznxio+zkFlbi8vi4/de9cXl8OO1WIhxWoiNstZ7LV+X24vX6NUu6SBOjMUsiElJ1BSUI3G3XsVUcF9Xxms/nx2w2Bccz+X4KSR6vj1c/+YH84iqiI2x8+2MWUU4rA3qlsmZzDpn55cz8amud73fvC0trrUttFphNvVPreLbsLmDZuv34DejYMo6yKg9Ou4XfXtqT6AgbDruV5vER5BVXkpIQidNhZcvuAj5cuJ0LzmzDub1bHtsFEpFTjlqW6qGWJZHGVz3zuc/nZ8m6/Sz+fh8+n8HpXZqzIT2PDdvz8Pr8mEzQPCGSkjIXPr+B1+fnWH+aRTistE2JYU92CZWuwFxVrZOjSU6IJCUxkkinlQvObENyQgSRTluNfStdXr7fkoPZbKJXpySiI2zsyyllb3Yp/XumYjlMuBSRE0fdcI1IYUkk/BiGgd8Ar8+Pw2bB5zcwEQgtW3cXsmlXPjsPFBMf7WDkgHZEOKxszigkNSmSZesPsHD1Xlw/Td4JYLOa8Xj9wa9bJkWRVVBx2C7CZnFOkuIj2JtdSqTDSpXbR1llYGoGq8VMYpyTvKJK/H6D5IQIurZL5PwzWmGzWjCZoKzSQ0KMg1bJ0ezJKuWjr3eQV1TJwF4tad8ylhaJkaT9NNv7D+l5GAb06pTEnqwSkuJrh7XjvZaA7mCUU47CUiNSWBI59Xi8gVap8koPfsMgLsrB5owCSivcWC1m+nRuzr6cUtZuzcHrM8gtqmTHviJ27S8Odh/+XFJ8BA6bhf25ZQ1S48BeqcRHO5i7IgOAxFgHBSUukuIjGHx6K+Ys30X71FhaNo+mpNxNuxYxxEbZGdirJWazieSEiDoDUEm5m0inFavFzAcLtjHzy63YbWaG9GtDv+4p9OzQTAPq5ZSgsNSIFJZE5FBllR72ZZeyP7eM2Cg7RaUumsVH0Kdzc8wmWLbuACt/zGTUwPa0TYlhc0YB67fn8t2PWfj8Bi63D7vNQpXbS0WVF6vFxIVntqFti1g27MilrMLD1t0Fx3xXYTWrxUxyQgQtkqKwWcxYrWYKiqvYnFGA3WYhPjowyP7nopxWfj2kM2d0TaaguIpWydGs25bL+/O3YbWaueGi7gw+oxVrtuSwfW8Rl57XEYfNgsvtxWIxY7WYsVkDzyosq3AT6bTVGuPm8/mZ/c0uCoqruHZUN+w2C4WlVUQ4rDjtJzaoHfpwazm1KSw1IoUlETmR6vrlvW1PIYvX7iO/uIpu7RLo37MFGQdKAHjj8034fH4G9mpJm5Rocgsr8fkN9maXsn1vIQUlrlrzY9WnS9t4xg3vysqNmazbnktuHQGqPhEOK4ZhBJ9JaDabaNcihooqL9kFFbRMiqJb+0Rio+zsOlDMrgMleH1+Kqq8AJyW1oxOreOZvWwndpuF/j1a0LFVHBE/dW+u3ZZDQXEV553eiv49W/Dx4h0UFFcx+IzWJMQ6iI2yk9Yqniq3l+9+zMJsNtGtfSLJCZG4PD5yCiponRxNRmYJ02atx+X28eiEgXXeNemwWRSkTiEKS41IYUlEThaGYVDp8mKzmikocbE3u5TiMhdenx+P14/fMOjbNRnDgKXr9rM5o4DbLu9Nq+bRQGBKiCXr9vP+/G2UlLuIjrCzP7eMmEg7lw7qQEGpiy9XZhzzIPrG1CYlhqJSV7Br1es7OCYttVkUp3dtTvvUWDLzylm3LZeMzBIinVa6tU/EbjWz80AJcVF2zuiaTFJ8BMvW7WfXgRJSEiPo1i6RH3flExVho3daErlFlXRpm4DdZsbl8XN65+b4/H7KKj1UubxERdgoLnOzJ6uENikxZBdU4DcMmsVGYGCwalM2w/u3pW2LWGxWM/afWuoMA+w2M2AKttbVxe3xUVzmpnlCRHCdYRjsyynD7fHRJiUGu81CSbmbb3/IJCHWyRldk0/5Gw8UlhqRwpKINGUVVR4cNgsWS+CXdXmlB6/Pj9NhxWyCbXuKsFhMtG8RiwGUVrjZuCOPmEg7aa3jWL89l4ISFzv2FrFtbyGXnZfGaR2b0bZFDHuyS1nw3R6yCiro0DKWSpcXr88gp7ACi9mEz2fQq1MSTruFWQu3k19cxeldmtM2JYYFq/dSXlnzeYfNEyJIiHGwY29RrW5Ms9lE25QYMjJLGunKHTurxYTXd/AEzGYT3dsnMrRfG0or3KTvLya1WRSRThsen4+5yzPIL65iYK9Uyis9lJS7qajyBLtZHXZLcH6yaqd3ac7VI7ricvv4cWc+fsOgdXI0P+4sICu/HIDkhEgcdgsutw+Xx0dxmQuXx8c1I7vRo0MiLrePSGegBdBkMmE1m9ibU8rW3YV0aZuA329QWFpF707NiYo4eFPCjr1FlFd6OC2tGV9/v4/mCRH07tS8wa+jwlIjUlgSEQm9KreX/OKqYCuYy+PDMAwKS1x4vD5iIu3ERTswm00Ul7nYuqcQs8kUvGuxV1oS8TEOikpdrN+ey64DxWRklpAQ4+SMrs3p2bEZS9cdYM43u+jfswVn92xBblElqzZlUVzmpkeHRPr3bMG2PYXsySqlZfMocgsrmf3NLmIj7STGOomJslFR5WXHviJsFjNOhxWP10ely4fDbqFzm3g27cwnKT6CTm3i2ZNVyr6cwA0BP2/9aghWi5kIh6XWQ7QtZtNhb1Q4EcwmiIqw0aJZFF6fn10HSmq9fu+1/TjvjFYN+r4KS41IYUlERA7H7QkM2D9U9ZQT1QPbC0uqsFjMxEbZKSl3E+W0YrGYMQyDskoPMT/NLu/zG3i8PvZll2EyEdwmwmFl8ff7WPlDJomxEaS1jqOgpAq3JzBlhcfjZ+hZbfhhZz6VLi9+v0FKYiRXDOlMpNPG7qwSyio87M4q4dzeLSksdTFr4XY2pufh8xn0656MyWRic0YBzeMjGHpWW8wm2J9bjmEYOOwWHHYLdquF77fmsPKHzMN2xUY4LMTHOIMP6bZaTBSWun7xOnZvn8jTvz/vOL4TtSksNSKFJRERkYNyCyspLnNRVummtMJD367JmM0mPF4/EQ4rNqs52H2LyURmXhker5+s/ArMJmjbIpYqt5ecggp6piXx/ZZs2qTE0KFlXIPWqcediIiISEg0T4ioMZi8WoTj4PKhE6e2To4BqBWGqr8efEbrE1Blwzv8EHsRERERUVgSERERqY/CkoiIiEg9FJZERERE6qGwJCIiIlKPsLobbufOnUyZMoU1a9Zgt9ux2WxceumlTJgwAbvdfsL2FRERETmcsGlZSk9PZ9y4cXzxxRe89NJLLFy4kAEDBjB16lTuuOOOE7aviIiISH3CJixNnjyZkpISUlJS6N27NwAjRowAYNGiRcyfP/+E7CsiIiJSn7AIS5WVlSxZsgSApKSk4PpmzZoFl+fOndvg+4qIiIj8krAYs5SRkYHP5wPA6XQG10dEHJwlND09vcH3hYNTotclMzOT1NTUX6heRERETmVh0bJUXl4eXLZYDj6U0Gw217lNQ+0rIiIi8kvComUpKioquFzdSgTg9/vr3Kah9oX6H7JXX6uTiIiINA1h0bLUrl27YKtQVVVVcH1lZWVwOS0trcH3FREREfklYdGyFBkZyaBBg1i8eDH5+fnB9QUFBcHlUaNGAfD888+zfPly7r//fvr163dU+x6tnJwcfD6fWphEREROIpmZmTWG5hyvsGhZArj//vuJjo4mKyuLjRs3Age7yAYPHsywYcMoLCxk+vTprF+/nldfffWo9j0WDocDq/XE5MnMzEwyMzNPyLGlbrrmoaHr3vh0zRufrnloHO66W61WHA5Hg72PyTAMo8GOdpzS09ODs3BXB5XRo0dz6623Bk/6jjvuYPny5Tz66KNcfPHFR7VvOKlurapvzJQ0LF3z0NB1b3y65o1P1zw0Guu6h0U3XLW0tDReeOGFerc53OtHsq+IiIjI0QqbbjgRERGRcKSwJCIiIlIPhSURERGReigsiYiIiNRDYUlERESkHmE1dYCIiIhIuFHLkoiIiEg9FJZERERE6qGwJCIiIlIPhSURERGReigsiYiIiNQjrJ4N1xTs3Lkz+MBfu92OzWbj0ksvZcKECdjt9lCXd9KZPXs2kydPJisrC4CtW7fW2uaTTz7h7bffJicnB7/fT4cOHbj11lsZNGhQje1KSkqYNm0a8+bNA8Dj8TB48GDuvPNOkpOTT/zJhLnnn3+elStXUl5eTklJCT6fj/bt2zNu3DhGjx6NyWQKbuv3+3n77beZNWsWpaWleDweevbsyaRJk+jdu3eN42ZnZzNlyhSWLl2KzWYDYPjw4UyaNImYmJhGPcdw88EHHzBnzhzy8vIwDIMDBw6QmJjIOeecw29/+1vat28f3Faf8xMjKyuLiy++mPLyciDwwNbWrVsHX9d1bxjffvstN9xwQ52v3XLLLdx7771ACH+2GNJoduzYYfTr18/o0qWLsX79esMwDOORRx4xunTpYtx6660hru7kUlBQYFxzzTXGddddZ/Tv39/o0qWL0aVLl1rb/etf/zK6dOlijBkzxnC5XEZRUZFx7rnnGt26dTM+//zz4HZVVVXGmDFjjC5duhj//ve/DcMwjM8//9zo0qWLceGFFxoFBQWNdm7h6pxzzjH+9re/GT6fzzAMw5g6dWrwuj/22GM1tq3+XE+YMMHw+/3G3r17jd69exu9evUyVq1aFdwuPz/fOP/8840uXboYc+bMMQzj4Pds7NixhsvlarwTDEO/+93vjHvuuSd4HTZv3mz06dPH6NKlizFw4ECjvLzcMAx9zk+kCRMmBD/nXbp0Mfbu3Rt8Tde94axcudI47bTTjP79+9f678UXXwxuF6qfLeqGa0STJ0+mpKSElJSUYAIeMWIEAIsWLWL+/PmhLO+kUlFRwQ033MDbb79NVFRUndvk5ubywgsvAHD++edjt9uJi4vj7LPPxu/389hjj+F2uwGYMWMGmzdvBgJ/eQAMGzYMk8nE/v37eemllxrhrMJbu3btmDRpEmZz4MfGrbfeGvxr7Z133qGiogKAH374gXfffRc4eA1bt25N9+7dcblc/P3vfw8ec9q0aWRmZmI2mxk6dChw8N/Ejz/+yMyZMxvt/MLR9ddfz3333Rdsde7WrRsdO3YEID8/n6ysLH3OT6DZs2eza9cu+vTpU+s1XfeGd8kll/Dtt9/W+m/ixIlAaH+2KCw1ksrKSpYsWQJAUlJScH2zZs2Cy3Pnzm30uk5WrVq1YuTIkfVus3DhQjweD1Dzmlcv5+fns2rVKgC++uqr4OvV3xO73U5sbCwAX3zxRcMVf5KaOXMmiYmJwa9tNlvw+ng8nuC1rutawsHrvmXLFjIyMgD48ssvAYiNjQ0GgkO/V039ug8cOJCUlJTg10uXLmXbtm3B19q3b6/P+QlSUFDAE088waOPPorD4aj1uq57w8vMzORPf/oTl19+OUOHDuXWW29l0aJFwddD+bNFYamRZGRk4PP5AHA6ncH1ERERweX09PRGr+tUtmPHjuDyodf80OXqbQ7d9tDvSfW2OTk5lJaWnrBaT0YlJSUUFBQA0KtXL+Li4oBfvpbV25SUlJCbm1vrtUOX9W8iYOnSpQwcOJCbb74Zv9/P+PHjeeWVVzCbzfqcnyBPPPEEF154IQMGDKjzdV33hmWxWHC5XPz+97/nww8/5LbbbuPrr7/mtttu41//+hcQ2p8tCkuNpHpwIAQ+FNWquzR+vo0cv+puIah5zQ9drr7mR7OtBLz55psYhkFiYiKPP/54cP2h1/LQz/fPr6Wu+ZE777zzWL58OdOnT8dqtfLuu+9yww034HK59Dk/ARYvXszKlSt54IEHDruNrnvD6tevH++++y4pKSmYTCauvPJKOnXqBMDUqVPJyckJ6c8WhaVGcui4muoWJgiM7K9rGzl+kZGRweVDr/mhy9XX/Gi2Ffj88895+eWX6du3L7NmzaJr167B1w69lod+vn9+LXXNj47JZGLIkCFcccUVAKxdu5ZZs2bpc97AysrK+Otf/8rDDz8c7Cari677iVc9Ps/j8bBu3bqQ/mxRWGok7dq1C6baqqqq4PrKysrgclpaWqPXdSo79Hoees0PXa7+y+XQbQ/9nlRvm5yc3ORvYwfwer08++yz/PnPf+aBBx5gxowZtGrVih07dgQHs/7StYTAdY+NjaV58+a1Xjt0uan/m9i7d2+tddWfWYDt27frc97Ali1bhsfj4eWXX2bMmDGMGTOGH374Ifj6hAkTGDNmjK57A8vNzcXr9dZYd+h0JF6vN6Q/WxSWGklkZGRw3o38/Pzg+uoxHwCjRo1q9LpOZRdeeCFWa2AqsUOvefVyQkICZ511FnDwDhU4+D1xu93BcQS/NJi8KdixYwfjxo1jy5YtzJ49mxtuuCHYFD5hwgRycnKAmteyruvetWvX4PxA1duWlJQEw9ah+zT1fxOXX3452dnZNdZVzykGgQGr+pw3rFGjRrFs2TI++eST4H+nnXZa8PVXXnmFTz75RNe9gd19991s2rSpxrpdu3YBgdDUq1evkP5sUVhqRPfffz/R0dFkZWWxceNGIDDBGcDgwYMZNmxYKMs75aSkpDBp0iQAlixZEvzh9N1332EymfjTn/4UvEviuuuuo0uXLgDBSeMWLVqE3+8nNTWV22+/PTQnEUbGjh3LDz/8wPr16xk7dixnn3128L/MzMzgdr179+bKK68EDn6+Dxw4wObNm7Hb7fz5z38Objtx4kRSUlLw+/0sXLiwxj7du3fn6quvbqzTC0uGYfDMM88Ef9hv2bKF9957DwgEpSuvvFKf8xDRdW94b775ZvAOwzlz5gTv/Lz66qtp06ZNSH+2mAzDMI7v9ORopKenB2fwdjgcWK1WRo8eza233lrn7alyeFdccQVVVVVkZGQE/4F17twZgLfffpuEhAQAPv74Y9566y1yc3MxDIN27doxYcIEzj///BrHKy4u5sUXX2T+/PmYTCY8Hg+DBg3iD3/4Q43bt5uqQ8cl1eXQmY39fj9vvfUWs2bNoqysDLfbTY8ePfj9739fa86arKys4Cy7drsdwzAYNmwYv//97+sdM9IUvPDCC6xatSr42c3KyqJFixYMGjSICRMm1Phc6nPe8L766iteeOEF9u3bF+z2ad++PaeddhrPPPMMoOveUGbNmsXcuXPJzs7G5XKRk5NDWloaV1xxBVdffXWwSy5UP1sUlkRERETqoW44ERERkXooLImIiIjUQ2FJREREpB4KSyIiIiL1UFgSERERqYfCkoiIiEg9FJZERERE6qGwJCIiIlIPa6gLEBE5WVVVVTFu3DgyMzOJjo4OPlZBRE4tmsFbRMJSdRDJy8sjLy+PtLQ0bDZbjW0qKipo0aIFb7/9doiqDHjwwQf57rvvFJZETlFqWRKRsOR0Ovnkk0+YOnUqL774Iq+88krw2XPVvv32W1588cUQVSgiTYXGLInISatLly7cfffdoS5DRE5xalkSkZPSkCFDeOuttzjjjDNYuXIlTz75JOnp6VxyySW0bt2ar7/+mszMTFq0aMGDDz5I//79a+y/fPlypk2bRlZWFn6/n06dOnHXXXfRo0ePGtv98MMPPP/886SnpxMbG4vFYuGCCy7guuuuIzExsdYx//Wvf7F3717i4+P5y1/+UutJ6CJy8lHLkoic9AYMGMAnn3xCcnIyX375JXFxcXz44YcsW7aMbt26cdNNN5GRkRHcfsGCBdx0002MHj2aBQsWsHDhQjp37sw111zDjz/+GNxu48aNXHvttfTs2ZOFCxfyySefcP/99/PKK6/w/fff16ihuLiYpUuX8sYbbzB//nxat27N3Xffjc/na6zLICIniMKSiJwUJkyYwJgxY4L/5eTk1LldcnIy119/PQBms5l7770XwzB46aWXADAMg8cff5yuXbty9dVXA2AymfjDH/6A0+nkH//4R/BYTz/9NFFRUUyaNAmTyQQEgtmwYcOwWCw13re8vJxbbrkFk8mE2WzmoosuYt++fezdu7fBr4WINC51w4nISeHnA7yHDBlS53ZdunQJBhuAxMREWrduzdq1awHYtWsX+/fvZ9CgQTX2s9vt9OzZkxUrVlBVVYVhGKxevZpzzjmn1l14zz//fK33jY+Pr9EtFx8fD0BeXh7t27c/mlMVkTCjsCQiJ6XD3aYfHR1da118fDybNm0CoLCwMLiuru18Ph/FxcUA+P3+OrerS2RkZI2vzeZAw7264UROfgpLInJKKS0trbWusLCQlJQUABISEgAoKiqqtV1RUREWi4W4uDgMw8BsNte5nYg0LRqzJCInrczMTMaOHVtj3fbt22t8XVBQwP79+znjjDMA6NChA61atWLjxo01tnO73WzatIl+/frhdDqJiIigX79+bN68GY/HU2PbRx55hNmzZ5+AMxKRcKSwJCInrUO7zKqVlZXx1ltvAYFutGeeeQaTycTtt98OBAZzP/zww2zZsoX3338fCAz6njp1KpWVlTzwwAPBY913332UlZXVmPjy66+/ZuHChZx99tkn+vREJEzocSciEpYqKyu55JJLKCkpobS0lJSUFKzWmiMHvF4vVqs1OH5pyJAh9O/fn65duzJnzhwOHDhASkrKYedZevHFF8nKysIwDNLS0rjrrrvo2bNnje1++OEHnnvuOdLT04mLi6N58+bcd999dO3aFYArr7yS3bt3U1FRQVpaGlOnTuXrr7/m7bffZs+ePbRt25Yrr7ySCRMmnMCrJSInksKSiJwyqsPSU089FepSROQUom44ERERkXooLImIiIjUQ2FJRE56K1euDM7qvXDhQsaMGYPb7Q51WSJyitCYJREREZF6qGVJREREpB4KSyIiIiL1UFgSERERqYfCkoiIiEg9FJZERERE6qGwJCIiIlIPhSURERGReigsiYiIiNTj/wHpKy+IsFhVMwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制训练集和验证集的损失曲线\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 701, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85522, 2)\n",
      "(85522, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_reshaped = y_pred.reshape(-1, 2)\n",
    "print(y_pred_reshaped.shape)\n",
    "\n",
    "y_test_reshaped = y_test.reshape(-1, 2)\n",
    "print(y_test_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过inverse_transform方法将标准化后的输出还原为原始值\n",
    "y_pred_reshaped = transfer2.inverse_transform(y_pred_reshaped)\n",
    "\n",
    "# 同样，如果想要还原测试集中的真实值\n",
    "y_test_reshaped = transfer2.inverse_transform(y_test_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85522,)\n",
      "(85522,)\n",
      "(85522,)\n",
      "(85522,)\n"
     ]
    }
   ],
   "source": [
    "# 提取前701个的第一列和第二列\n",
    "# n_pred = y_pred_reshaped[:, 0]\n",
    "# n_test = y_test_reshaped[:, 0]\n",
    "# k_pred = y_pred_reshaped[:, 1]\n",
    "# k_test = y_test_reshaped[:, 1]\n",
    "PSI_pred = y_pred_reshaped[:, 0]\n",
    "PSI_test = y_test_reshaped[:, 0]\n",
    "DELTA_pred = y_pred_reshaped[:, 1]\n",
    "DELTA_test = y_test_reshaped[:, 1]\n",
    "\n",
    "# 打印形状\n",
    "# print(n_pred.shape)  # 输出(122, 701)\n",
    "# print(n_test.shape)  # 输出(122, 701)\n",
    "# print(k_pred.shape)  # 输出(122, 701)\n",
    "# print(k_test.shape)  # 输出(122, 701)\n",
    "print(PSI_pred.shape)  # 输出(122, 701)\n",
    "print(PSI_test.shape)  # 输出(122, 701)\n",
    "print(DELTA_pred.shape)  # 输出(122, 701)\n",
    "print(DELTA_test.shape)  # 输出(122, 701)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSI_test MSE:  0.8446353987873706\n",
      "PSI_test RMSE:  0.919040477230122\n",
      "PSI_test MAE:  0.62304795458938\n",
      "PSI_test R2 score:  0.9630765779043234\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(PSI_test, PSI_pred)\n",
    "print(\"PSI_test MSE: \", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"PSI_test RMSE: \", rmse)\n",
    "mae = mean_absolute_error(PSI_test, PSI_pred)\n",
    "print(\"PSI_test MAE: \", mae)\n",
    "r2 = r2_score(PSI_test, PSI_pred)\n",
    "print(\"PSI_test R2 score: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELTA_test MSE:  270.0815294637245\n",
      "DELTA_test RMSE:  16.434157400479176\n",
      "DELTA_test MAE:  4.872359750394785\n",
      "DELTA_test R2 score:  0.9212218785166127\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(DELTA_test, DELTA_pred)\n",
    "print(\"DELTA_test MSE: \", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"DELTA_test RMSE: \", rmse)\n",
    "mae = mean_absolute_error(DELTA_test, DELTA_pred)\n",
    "print(\"DELTA_test MAE: \", mae)\n",
    "r2 = r2_score(DELTA_test, DELTA_pred)\n",
    "print(\"DELTA_test R2 score: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 701, 1)\n",
      "(122, 701, 1)\n",
      "(122, 701, 1)\n",
      "(122, 701, 1)\n"
     ]
    }
   ],
   "source": [
    "samples_per_slice = 701\n",
    "n_samples = PSI_pred.shape[0] // samples_per_slice\n",
    "feature_slices_pred = PSI_pred[:n_samples * samples_per_slice].reshape((n_samples, samples_per_slice, 1))\n",
    "PSI_pred = np.stack(feature_slices_pred, axis=0)\n",
    "print(PSI_pred.shape) \n",
    "\n",
    "samples_per_slice = 701\n",
    "n_samples = PSI_test.shape[0] // samples_per_slice\n",
    "feature_slices_test = PSI_test[:n_samples * samples_per_slice].reshape((n_samples, samples_per_slice, 1))\n",
    "PSI_test = np.stack(feature_slices_test, axis=0)\n",
    "print(PSI_test.shape)\n",
    "\n",
    "samples_per_slice = 701\n",
    "n_samples = DELTA_pred.shape[0] // samples_per_slice\n",
    "feature_slices_pred = DELTA_pred[:n_samples * samples_per_slice].reshape((n_samples, samples_per_slice, 1))\n",
    "DELTA_pred = np.stack(feature_slices_pred, axis=0)\n",
    "print(DELTA_pred.shape) \n",
    "\n",
    "samples_per_slice = 701\n",
    "n_samples = DELTA_test.shape[0] // samples_per_slice\n",
    "feature_slices_test = DELTA_test[:n_samples * samples_per_slice].reshape((n_samples, samples_per_slice, 1))\n",
    "DELTA_test = np.stack(feature_slices_test, axis=0)\n",
    "print(DELTA_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 生成x坐标轴数据\n",
    "wavelength = range(200, 901)\n",
    "\n",
    "# 遍历121个数据，分别绘制四条曲线\n",
    "for i in range(122):\n",
    "    plt.figure()\n",
    "    # plt.plot(wavelength, n_pred[i], 'b-', label='n_pred')\n",
    "    # plt.plot(wavelength, n_test[i], 'b--', label='n_test')\n",
    "    # plt.plot(wavelength, k_pred[i], 'r-', label='k_pred')\n",
    "    # plt.plot(wavelength, k_test[i], 'r--', label='k_test')\n",
    "    plt.plot(wavelength, PSI_pred[i], 'y-', label='PSI_pred')\n",
    "    plt.plot(wavelength, PSI_test[i], 'y--', label='PSI_test')\n",
    "    plt.plot(wavelength, DELTA_pred[i], 'g-', label='DELTA_pred')\n",
    "    plt.plot(wavelength, DELTA_test[i], 'g--', label='DELTA_test')\n",
    "    \n",
    "    plt.xlabel('Wavelength[nm]')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Data {}'.format(i+1))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
